{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Inference and Evaluation of BERT-single.ipynb","provenance":[{"file_id":"https://github.com/Nix07/Utilizing-BERT-for-Aspect-Based-Sentiment-Analysis/blob/master/InferenceAndEvaluationonSentiHood.ipynb","timestamp":1595985479349}],"collapsed_sections":["heq1V0lTx_in","nOZIOy_6i3A8","lbPOH-qKnMpt","hAe7SdqhoGYX","xi3HhPWl9AYY","la6Qog6WzOY6","GMTW-2QW5qc9","yeKKnFqcgsqu","HrFzIn4Jje3S"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bf7b696bc6a74b4cbdf7d543fa531b59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18ad1625d310456e901c6e0fe3c003cf","IPY_MODEL_487cfcc73a7046cab6e2ed53c5c69b92","IPY_MODEL_d3c9e2a4be8c41c58c518eb2e1039f1c"],"layout":"IPY_MODEL_332bd38c5009481896141a22b525f661"}},"18ad1625d310456e901c6e0fe3c003cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80bbdfb0db214d7094fc073f90867258","placeholder":"​","style":"IPY_MODEL_72a4c9ab6f1743f09fe59a43f9fbbf0e","value":"Downloading: 100%"}},"487cfcc73a7046cab6e2ed53c5c69b92":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a74e4fa0e754142bd114101c18f5057","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_745b047511134d488253d5f398a6cb6a","value":231508}},"d3c9e2a4be8c41c58c518eb2e1039f1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad685cb5419e46369c4d7b02f3cbb9b9","placeholder":"​","style":"IPY_MODEL_7c962f4a073b4aeaafdc2b8d90747a74","value":" 226k/226k [00:00&lt;00:00, 883kB/s]"}},"332bd38c5009481896141a22b525f661":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80bbdfb0db214d7094fc073f90867258":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72a4c9ab6f1743f09fe59a43f9fbbf0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a74e4fa0e754142bd114101c18f5057":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"745b047511134d488253d5f398a6cb6a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad685cb5419e46369c4d7b02f3cbb9b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c962f4a073b4aeaafdc2b8d90747a74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ea1708d17744d21b4f82964042210f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7917b83500142b9ba884dec9d6b24f7","IPY_MODEL_d481734315f740ffb7fd797e1a3e026c","IPY_MODEL_d56b010de8534745989dabf5aa279b13"],"layout":"IPY_MODEL_fd9cbc7121064742be70ecd1ce637027"}},"d7917b83500142b9ba884dec9d6b24f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_209169cc4b5449fd93b9e468fb4dc290","placeholder":"​","style":"IPY_MODEL_5709aa50c2ce4af285bf583e93d85692","value":"Downloading: 100%"}},"d481734315f740ffb7fd797e1a3e026c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80c461897ebf4506b49eccc9302e6995","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_36855833cce445178d938e983bcfa661","value":28}},"d56b010de8534745989dabf5aa279b13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d08ca445dcab49e3ad8e2506697b9686","placeholder":"​","style":"IPY_MODEL_6e77e7ca4ff745ad8768a2ee9eed36f1","value":" 28.0/28.0 [00:00&lt;00:00, 409B/s]"}},"fd9cbc7121064742be70ecd1ce637027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"209169cc4b5449fd93b9e468fb4dc290":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5709aa50c2ce4af285bf583e93d85692":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80c461897ebf4506b49eccc9302e6995":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36855833cce445178d938e983bcfa661":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d08ca445dcab49e3ad8e2506697b9686":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e77e7ca4ff745ad8768a2ee9eed36f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6fc1751240446d09e7ba5c1b3d0b9d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6416853af83f418ca33707ba3bcb95f2","IPY_MODEL_36439398a50c48159f8d5b4015cf8c02","IPY_MODEL_ecb45487ae72446497bd1bc9909e6c17"],"layout":"IPY_MODEL_a12384b6faf24d9f8ebc8aae0430675e"}},"6416853af83f418ca33707ba3bcb95f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_952da5c83d1b4936aa0e8f81920a2a98","placeholder":"​","style":"IPY_MODEL_80ff1fc250db465e9ad8d25bc73e3585","value":"Downloading: 100%"}},"36439398a50c48159f8d5b4015cf8c02":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_41942cd4d5fd460a89d38b2fdc85d7a4","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a9c0003ed84447c5b3f682c966c6b8f3","value":570}},"ecb45487ae72446497bd1bc9909e6c17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_039ee38c8b8b41e3bbb49322068b7b96","placeholder":"​","style":"IPY_MODEL_b3e01f8ffd7c42958e0f41d4ac2e5e5c","value":" 570/570 [00:00&lt;00:00, 6.66kB/s]"}},"a12384b6faf24d9f8ebc8aae0430675e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"952da5c83d1b4936aa0e8f81920a2a98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80ff1fc250db465e9ad8d25bc73e3585":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41942cd4d5fd460a89d38b2fdc85d7a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9c0003ed84447c5b3f682c966c6b8f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"039ee38c8b8b41e3bbb49322068b7b96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3e01f8ffd7c42958e0f41d4ac2e5e5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"id":"xEZrNmBQD--R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653840950032,"user_tz":-420,"elapsed":27887,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}},"outputId":"3b67244e-77cb-48fb-e383-9c0db9a86b3c"},"source":["# Install dependencies\n","!pip uninstall -y tensorflow\n","!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n","Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n","  Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 8.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 62.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 58.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"]}]},{"cell_type":"code","metadata":{"id":"t2Tg9H2qFro9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653840969272,"user_tz":-420,"elapsed":19257,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}},"outputId":"4d1765dc-9e01-4c2d-f6b4-276c7868b497"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"WXP5sn3DEFJI","executionInfo":{"status":"ok","timestamp":1653840972561,"user_tz":-420,"elapsed":3298,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["import json\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import numpy as np\n","import transformers\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, accuracy_score\n","from transformers import BertModel, BertTokenizer\n","\n","import logging\n","logging.basicConfig(level=logging.ERROR)\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"apq1bd74EIds","executionInfo":{"status":"ok","timestamp":1653840972561,"user_tz":-420,"elapsed":9,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["class SentimentClassifier(nn.Module):\n","  \"\"\"\n","  This class defines the model architecture which is simply a fully-connected\n","  layer on top of a pre-trained BERT model. \n","  \"\"\"\n","\n","  def __init__(self, BERT_MODEL):\n","    super(SentimentClassifier, self).__init__()\n","    self.bert = BertModel.from_pretrained(BERT_MODEL)\n","    self.drop = nn.Dropout(p=0.1)\n","    self.out = nn.Linear(self.bert.config.hidden_size, 3) # Number of output classes = 3\n","\n","  def forward(self, ids, mask, token_type_ids):\n","    last_hidden_state, pooled_output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n","    output = self.drop(pooled_output)\n","    return self.out(output)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"heq1V0lTx_in"},"source":["# Inference on BERT-single Testing Set\n","\n","The best trained model (based on validation set) is utilized to perform inference on testing sets corresponding to every `location-aspect`. \n","\n","The predicted values are stored to perform evaluation. "]},{"cell_type":"code","metadata":{"id":"8EWrZVNXEUTC","executionInfo":{"status":"ok","timestamp":1653840972562,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["class SentiHood:\n","  \"\"\"\n","  This class tokenizes the input text using the pre-trained BERT tokenizer \n","  (wordpiece) and returns the corresponding tensors.\n","  \"\"\"\n","  \n","  def __init__(self, opinions_id, text, targets, tokenizer, max_len):\n","    self.opinions_id = opinions_id\n","    self.text = text\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","    self.targets = targets\n","\n","  def __len__(self):\n","    return len(self.targets)\n","\n","  def __getitem__(self, item):\n","    opinions_id = self.opinions_id[item]\n","    text = str(self.text[item])\n","    targets = self.targets[item]\n","\n","    inputs = self.tokenizer.encode_plus(\n","        text,\n","        add_special_tokens = True,\n","        max_length = self.max_len,\n","        pad_to_max_length = True\n","    )\n","\n","    ids = inputs[\"input_ids\"]\n","    mask = inputs[\"attention_mask\"]\n","    token_type_ids = inputs[\"token_type_ids\"]\n","\n","    return {\n","        \"ids\": torch.tensor(ids, dtype=torch.long),\n","        \"mask\": torch.tensor(mask, dtype=torch.long),\n","        \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n","        \"targets\": torch.tensor(targets, dtype=torch.long),\n","        \"opinions_id\": torch.tensor(opinions_id, dtype=torch.long)\n","    }"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"2MroNpgUSDC_","executionInfo":{"status":"ok","timestamp":1653840972562,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["def infer_loop_function(data_loader, model, device, location, aspect):\n","  \"\"\"\n","  This function performs the inference on testing sets and stores the predicted\n","  values.\n","  \"\"\"\n","\n","  model.eval()\n","\n","  df_pred = pd.DataFrame({\"id\": [], \"predicted\": [], \"actual\": []})\n","\n","  ii = 0\n","  for bi, d in tqdm(enumerate(data_loader), total=len(data_loader), ncols=80, leave=False):\n","    opinions_id = d[\"opinions_id\"]\n","    ids = d[\"ids\"]\n","    mask = d[\"mask\"]\n","    token_type_ids = d[\"token_type_ids\"]\n","    targets = d[\"targets\"]\n","\n","    opinions_id = opinions_id.to(device, dtype=torch.long)\n","    ids = ids.to(device, dtype=torch.long)\n","    mask = mask.to(device, dtype=torch.long)\n","    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","    targets = targets.to(device, dtype=torch.long)\n","\n","    outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n","    _, predicted = torch.max(outputs, 1)\n","    \n","    predicted = predicted.detach().cpu().numpy()\n","    targets = targets.detach().cpu().numpy()\n","    opinions_id = opinions_id.detach().cpu().numpy()\n","\n","    for k in range(len(predicted)):\n","      df_pred.loc[ii] = [str(opinions_id[k]), str(predicted[k]), str(targets[k])]\n","      ii += 1\n","\n","  print(f\"{location}{aspect} DONE!\")\n","  save_path = '/content/drive/MyDrive/BERT-ABSA/Bert-single/PredictedData/Predicted' + str(location) + str(aspect) + '.csv'\n","  df_pred.to_csv(save_path, index=False)\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"IExOxqGGEU1Z","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bf7b696bc6a74b4cbdf7d543fa531b59","18ad1625d310456e901c6e0fe3c003cf","487cfcc73a7046cab6e2ed53c5c69b92","d3c9e2a4be8c41c58c518eb2e1039f1c","332bd38c5009481896141a22b525f661","80bbdfb0db214d7094fc073f90867258","72a4c9ab6f1743f09fe59a43f9fbbf0e","4a74e4fa0e754142bd114101c18f5057","745b047511134d488253d5f398a6cb6a","ad685cb5419e46369c4d7b02f3cbb9b9","7c962f4a073b4aeaafdc2b8d90747a74","0ea1708d17744d21b4f82964042210f1","d7917b83500142b9ba884dec9d6b24f7","d481734315f740ffb7fd797e1a3e026c","d56b010de8534745989dabf5aa279b13","fd9cbc7121064742be70ecd1ce637027","209169cc4b5449fd93b9e468fb4dc290","5709aa50c2ce4af285bf583e93d85692","80c461897ebf4506b49eccc9302e6995","36855833cce445178d938e983bcfa661","d08ca445dcab49e3ad8e2506697b9686","6e77e7ca4ff745ad8768a2ee9eed36f1","a6fc1751240446d09e7ba5c1b3d0b9d7","6416853af83f418ca33707ba3bcb95f2","36439398a50c48159f8d5b4015cf8c02","ecb45487ae72446497bd1bc9909e6c17","a12384b6faf24d9f8ebc8aae0430675e","952da5c83d1b4936aa0e8f81920a2a98","80ff1fc250db465e9ad8d25bc73e3585","41942cd4d5fd460a89d38b2fdc85d7a4","a9c0003ed84447c5b3f682c966c6b8f3","039ee38c8b8b41e3bbb49322068b7b96","b3e01f8ffd7c42958e0f41d4ac2e5e5c"]},"outputId":"87008247-3732-45fe-8108-7e05e17a37e2","executionInfo":{"status":"ok","timestamp":1653841397337,"user_tz":-420,"elapsed":424780,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["def run():\n","  \"\"\"\n","  This function defines the necessary hyperparameters and models. It also \n","  loads and tokenizes the testing dataset and execute the inference procedure.\n","  \"\"\"\n","  \n","  MAX_LEN = 140\n","  BATCH_SIZE = 24\n","  BERT_MODEL = 'bert-base-uncased'\n","\n","  locations = ['LOCATION1', 'LOCATION2']\n","  aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","\n","  for location in locations:\n","    for aspect in aspects:\n","      print(f\"Starting {location} {aspect}...\")\n","      testing_set_path = '/content/drive/MyDrive/BERT-ABSA/Bert-single/TestingData/' + str(location) + str(aspect) + '.csv'\n","\n","      df_test = pd.read_csv(testing_set_path)\n","      sentiment_mapping = {\n","          'Positive': 0,\n","          'Negative': 1,\n","          'None': 2\n","      }\n","      df_test['sentiment'] = df_test['sentiment'].map(sentiment_mapping)\n","      df_test = df_test.reset_index(drop=True)\n","\n","      tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n","\n","      test_dataset = SentiHood(\n","          opinions_id = df_test['id'].values,\n","          text = df_test['text'].values,\n","          targets = df_test['sentiment'].values,\n","          tokenizer = tokenizer,\n","          max_len = MAX_LEN\n","      )\n","\n","      test_data_loader = torch.utils.data.DataLoader(\n","          test_dataset,\n","          batch_size = BATCH_SIZE,\n","          shuffle = False\n","      )\n","\n","      device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","      print(f\"Device: {device}\")\n","\n","      model = torch.load('/content/drive/MyDrive/BERT-ABSA/Bert-single/LocationAspectModels/'+str(location)+str(aspect)+'/0.bin')\n","      infer_loop_function(data_loader=test_data_loader, model=model, device=device, location=location, aspect=aspect)\n","\n","if __name__ == \"__main__\":\n","  run()     "],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting LOCATION1 dining...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf7b696bc6a74b4cbdf7d543fa531b59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ea1708d17744d21b4f82964042210f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6fc1751240446d09e7ba5c1b3d0b9d7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/63 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION1dining DONE!\n","Starting LOCATION1 general...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/63 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION1general DONE!\n","Starting LOCATION1 green-nature...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/63 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION1green-nature DONE!\n","Starting LOCATION1 live...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/63 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION1live DONE!\n","Starting LOCATION1 multicultural...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/63 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION1multicultural DONE!\n","Starting LOCATION1 nightlife...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/63 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION1nightlife DONE!\n","Starting LOCATION1 price...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/63 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION1price DONE!\n","Starting LOCATION1 quiet...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/63 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION1quiet DONE!\n","Starting LOCATION1 safety...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/63 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION1safety DONE!\n","Starting LOCATION1 shopping...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/63 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION1shopping DONE!\n","Starting LOCATION1 touristy...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/63 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION1touristy DONE!\n","Starting LOCATION1 transit-location...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/63 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION1transit-location DONE!\n","Starting LOCATION2 dining...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION2dining DONE!\n","Starting LOCATION2 general...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION2general DONE!\n","Starting LOCATION2 green-nature...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION2green-nature DONE!\n","Starting LOCATION2 live...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION2live DONE!\n","Starting LOCATION2 multicultural...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION2multicultural DONE!\n","Starting LOCATION2 nightlife...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION2nightlife DONE!\n","Starting LOCATION2 price...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION2price DONE!\n","Starting LOCATION2 quiet...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION2quiet DONE!\n","Starting LOCATION2 safety...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION2safety DONE!\n","Starting LOCATION2 shopping...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION2shopping DONE!\n","Starting LOCATION2 touristy...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION2touristy DONE!\n","Starting LOCATION2 transit-location...\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["LOCATION2transit-location DONE!\n"]}]},{"cell_type":"markdown","metadata":{"id":"0FDyDb5McVga"},"source":["# BERT-single Evaluation"]},{"cell_type":"markdown","metadata":{"id":"nOZIOy_6i3A8"},"source":["### Creating a dataframe containing true labels corresponding to every `location-aspect` in the testing set."]},{"cell_type":"code","metadata":{"id":"7gGQrWzWdcVp","executionInfo":{"status":"ok","timestamp":1653841398542,"user_tz":-420,"elapsed":1214,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["df_true_location1 = pd.DataFrame({'id': [], 'location': [] , 'dining': [], 'general': [], 'green-nature': [], 'live': [], 'multicultural': [], 'nightlife': [], 'price': [], 'quiet': [], 'safety': [],'shopping': [], 'touristy': [], 'transit-location': []})\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","\n","for aspect in aspects:\n","  testing_set_path = '/content/drive/MyDrive/BERT-ABSA/Bert-single/TestingData/LOCATION1' + str(aspect) + '.csv'\n","\n","  df_test = pd.read_csv(testing_set_path)\n","  sentiment_mapping = {\n","      'Positive': 0,\n","      'Negative': 1,\n","      'None': 2\n","  }\n","  df_test['sentiment'] = df_test['sentiment'].map(sentiment_mapping)\n","  df_test = df_test.reset_index(drop=True)\n","\n","  df_true_location1[aspect] = df_test['sentiment']\n","\n","df_true_location1['location'] = 'LOCATION1'\n","df_true_location1['id'] = df_test['id']"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"mmqC_9F4icS0","executionInfo":{"status":"ok","timestamp":1653841398544,"user_tz":-420,"elapsed":19,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["df_true_location2 = pd.DataFrame({'id': [], 'location': [] , 'dining': [], 'general': [], 'green-nature': [], 'live': [], 'multicultural': [], 'nightlife': [], 'price': [], 'quiet': [], 'safety': [],'shopping': [], 'touristy': [], 'transit-location': []})\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","\n","for aspect in aspects:\n","  testing_set_path = '/content/drive/MyDrive/BERT-ABSA/Bert-single/TestingData/LOCATION2' + str(aspect) + '.csv'\n","\n","  df_test = pd.read_csv(testing_set_path)\n","  sentiment_mapping = {\n","      'Positive': 0,\n","      'Negative': 1,\n","      'None': 2\n","  }\n","  df_test['sentiment'] = df_test['sentiment'].map(sentiment_mapping)\n","  df_test = df_test.reset_index(drop=True)\n","\n","  df_true_location2[aspect] = df_test['sentiment']\n","\n","df_true_location2['location'] = 'LOCATION2'\n","df_true_location2['id'] = df_test['id']"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"e7uozDz6igHq","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1653841398545,"user_tz":-420,"elapsed":19,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}},"outputId":"3e615c1c-851d-46d3-918b-7af3f90fba38"},"source":["df_true = pd.concat([df_true_location1, df_true_location2])\n","df_true"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       id   location  dining  general  green-nature  live  multicultural  \\\n","0     153  LOCATION1       2        2             2     2              2   \n","1    1130  LOCATION1       2        0             2     2              2   \n","2    1271  LOCATION1       2        1             2     2              2   \n","3    1089  LOCATION1       2        1             2     2              2   \n","4     731  LOCATION1       2        2             2     2              2   \n","..    ...        ...     ...      ...           ...   ...            ...   \n","383  1431  LOCATION2       2        0             2     2              2   \n","384  1290  LOCATION2       2        0             2     2              2   \n","385   363  LOCATION2       2        2             2     2              2   \n","386  1304  LOCATION2       2        0             2     2              2   \n","387  1379  LOCATION2       2        0             2     2              2   \n","\n","     nightlife  price  quiet  safety  shopping  touristy  transit-location  \n","0            2      2      2       0         2         2                 2  \n","1            2      2      2       0         2         2                 2  \n","2            2      0      2       2         2         2                 2  \n","3            2      2      2       2         2         2                 2  \n","4            2      2      2       2         2         2                 2  \n","..         ...    ...    ...     ...       ...       ...               ...  \n","383          2      2      2       2         2         2                 2  \n","384          2      2      2       2         2         2                 2  \n","385          2      2      2       2         2         2                 2  \n","386          2      2      2       2         2         2                 2  \n","387          2      2      2       2         2         2                 2  \n","\n","[1879 rows x 14 columns]"],"text/html":["\n","  <div id=\"df-d7205d5d-6bad-4d3a-98ed-cf8dfdf9cc2f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>location</th>\n","      <th>dining</th>\n","      <th>general</th>\n","      <th>green-nature</th>\n","      <th>live</th>\n","      <th>multicultural</th>\n","      <th>nightlife</th>\n","      <th>price</th>\n","      <th>quiet</th>\n","      <th>safety</th>\n","      <th>shopping</th>\n","      <th>touristy</th>\n","      <th>transit-location</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>153</td>\n","      <td>LOCATION1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1130</td>\n","      <td>LOCATION1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1271</td>\n","      <td>LOCATION1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1089</td>\n","      <td>LOCATION1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>731</td>\n","      <td>LOCATION1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>383</th>\n","      <td>1431</td>\n","      <td>LOCATION2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>384</th>\n","      <td>1290</td>\n","      <td>LOCATION2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>385</th>\n","      <td>363</td>\n","      <td>LOCATION2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>386</th>\n","      <td>1304</td>\n","      <td>LOCATION2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>387</th>\n","      <td>1379</td>\n","      <td>LOCATION2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1879 rows × 14 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7205d5d-6bad-4d3a-98ed-cf8dfdf9cc2f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d7205d5d-6bad-4d3a-98ed-cf8dfdf9cc2f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d7205d5d-6bad-4d3a-98ed-cf8dfdf9cc2f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"lbPOH-qKnMpt"},"source":["### Creating dataframe containing predicted labels corresponding to every `location-aspect` in the testing set."]},{"cell_type":"code","metadata":{"id":"RjmSfHgskAuU","executionInfo":{"status":"ok","timestamp":1653841399734,"user_tz":-420,"elapsed":1202,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["df_predicted_location1 = pd.DataFrame({'id': [], 'location': [] , 'dining': [], 'general': [], 'green-nature': [], 'live': [], 'multicultural': [], 'nightlife': [], 'price': [], 'quiet': [], 'safety': [],'shopping': [], 'touristy': [], 'transit-location': []})\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","\n","for aspect in aspects:\n","  testing_set_path = '/content/drive/MyDrive/BERT-ABSA/Bert-single/PredictedData/PredictedLOCATION1' + str(aspect) + '.csv'\n","\n","  df_test = pd.read_csv(testing_set_path)\n","  df_test = df_test.reset_index(drop=True)\n","\n","  df_predicted_location1[aspect] = df_test['predicted']\n","\n","df_predicted_location1['location'] = 'LOCATION1'\n","df_predicted_location1['id'] = df_test['id']"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"1BZ-c0EZnpez","executionInfo":{"status":"ok","timestamp":1653841399739,"user_tz":-420,"elapsed":32,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["df_predicted_location2 = pd.DataFrame({'id': [], 'location': [] , 'dining': [], 'general': [], 'green-nature': [], 'live': [], 'multicultural': [], 'nightlife': [], 'price': [], 'quiet': [], 'safety': [],'shopping': [], 'touristy': [], 'transit-location': []})\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","\n","for aspect in aspects:\n","  testing_set_path = '/content/drive/MyDrive/BERT-ABSA/Bert-single/PredictedData/PredictedLOCATION2' + str(aspect) + '.csv'\n","\n","  df_test = pd.read_csv(testing_set_path)\n","  df_test = df_test.reset_index(drop=True)\n","\n","  df_predicted_location2[aspect] = df_test['predicted']\n","\n","df_predicted_location2['location'] = 'LOCATION2'\n","df_predicted_location2['id'] = df_test['id']"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"VfaRIGb4oIHx","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1653841399740,"user_tz":-420,"elapsed":30,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}},"outputId":"f40e66b6-4226-4e96-9b43-2d42d7f37e6c"},"source":["df_predicted = pd.concat([df_predicted_location1, df_predicted_location2])\n","df_predicted"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       id   location  dining  general  green-nature  live  multicultural  \\\n","0     153  LOCATION1       2        2             2     2              2   \n","1    1130  LOCATION1       2        0             2     2              2   \n","2    1271  LOCATION1       2        1             2     2              2   \n","3    1089  LOCATION1       2        1             2     2              2   \n","4     731  LOCATION1       2        2             2     2              2   \n","..    ...        ...     ...      ...           ...   ...            ...   \n","383  1431  LOCATION2       2        1             2     2              2   \n","384  1290  LOCATION2       2        0             2     2              2   \n","385   363  LOCATION2       2        2             2     2              2   \n","386  1304  LOCATION2       2        0             2     2              2   \n","387  1379  LOCATION2       2        0             2     2              2   \n","\n","     nightlife  price  quiet  safety  shopping  touristy  transit-location  \n","0            2      2      2       0         2         2                 2  \n","1            2      2      2       0         2         2                 2  \n","2            2      0      2       2         2         2                 2  \n","3            2      2      2       2         2         2                 2  \n","4            2      2      2       2         2         0                 2  \n","..         ...    ...    ...     ...       ...       ...               ...  \n","383          2      1      2       2         2         2                 2  \n","384          2      2      2       0         2         2                 2  \n","385          2      2      2       0         2         2                 2  \n","386          2      1      2       2         2         2                 2  \n","387          2      1      2       2         2         2                 2  \n","\n","[1879 rows x 14 columns]"],"text/html":["\n","  <div id=\"df-b5efd6c5-c99b-4988-a4d9-a6267b3d210e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>location</th>\n","      <th>dining</th>\n","      <th>general</th>\n","      <th>green-nature</th>\n","      <th>live</th>\n","      <th>multicultural</th>\n","      <th>nightlife</th>\n","      <th>price</th>\n","      <th>quiet</th>\n","      <th>safety</th>\n","      <th>shopping</th>\n","      <th>touristy</th>\n","      <th>transit-location</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>153</td>\n","      <td>LOCATION1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1130</td>\n","      <td>LOCATION1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1271</td>\n","      <td>LOCATION1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1089</td>\n","      <td>LOCATION1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>731</td>\n","      <td>LOCATION1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>383</th>\n","      <td>1431</td>\n","      <td>LOCATION2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>384</th>\n","      <td>1290</td>\n","      <td>LOCATION2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>385</th>\n","      <td>363</td>\n","      <td>LOCATION2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>386</th>\n","      <td>1304</td>\n","      <td>LOCATION2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>387</th>\n","      <td>1379</td>\n","      <td>LOCATION2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1879 rows × 14 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5efd6c5-c99b-4988-a4d9-a6267b3d210e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b5efd6c5-c99b-4988-a4d9-a6267b3d210e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b5efd6c5-c99b-4988-a4d9-a6267b3d210e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"hAe7SdqhoGYX"},"source":["## Evaluation"]},{"cell_type":"markdown","metadata":{"id":"xi3HhPWl9AYY"},"source":["### Sentiment Accuracy"]},{"cell_type":"code","metadata":{"id":"4nyHEEn12Fax","executionInfo":{"status":"ok","timestamp":1653841399741,"user_tz":-420,"elapsed":27,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["def compute_sentiment_accuracy(df_true, df_predicted):\n","  \"\"\"This function computes the sentiment classfication accuracy\"\"\"\n","\n","  count = 0\n","  total = 0\n","\n","  for aspect in ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']:\n","    count += np.sum(df_true[aspect].values == df_predicted[aspect].values)\n","    total += df_true.shape[0]\n","\n","  accuracy = float(count)/float(total) * 100\n","  return round(accuracy, 2)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssYrZOjq_UOl","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cb7555b0-54cf-43b4-8433-5ddc0f01937f","executionInfo":{"status":"ok","timestamp":1653841399742,"user_tz":-420,"elapsed":26,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["print(f\"Sentiment Accuracy: {compute_sentiment_accuracy(df_true, df_predicted)}\")"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment Accuracy: 92.82\n"]}]},{"cell_type":"markdown","metadata":{"id":"la6Qog6WzOY6"},"source":["### Aspect Accuracy"]},{"cell_type":"code","metadata":{"id":"jhbY0OqbodLM","executionInfo":{"status":"ok","timestamp":1653841399742,"user_tz":-420,"elapsed":21,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["def compute_aspect_accuracy(df_true, df_predicted):\n","  \"\"\"\n","  This function computes the strict aspect accuracy.\n","  0 => Represents that the aspect has not been detected by the model.\n","  1 => Represents that the aspect has been detected by the model.\n","  \"\"\"\n","  \n","  df_true = df_true.replace([0, 1], 1).replace(2, 0)\n","  df_predicted = df_predicted.replace([0, 1], 1).replace(2, 0)\n","\n","  count = 0\n","  total = 0\n","\n","  for i in range(df_true.shape[0]):\n","    true_values = df_true.iloc[i].values[2:]\n","    predicted_values = df_predicted.iloc[i].values[2:]\n","\n","    if (true_values == predicted_values).all():\n","      count += 1\n","    total += 1\n","\n","  accuracy = float(count)/float(total)*100\n","  return round(accuracy, 2)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"31h0xD8Uwf82","colab":{"base_uri":"https://localhost:8080/"},"outputId":"866af2a5-1d04-4579-a312-6be17ba2b0f7","executionInfo":{"status":"ok","timestamp":1653841400264,"user_tz":-420,"elapsed":541,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["print(f\"Aspect Accuracy (strict): {compute_aspect_accuracy(df_true, df_predicted)}%\")"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Aspect Accuracy (strict): 48.06%\n"]}]},{"cell_type":"markdown","metadata":{"id":"GMTW-2QW5qc9"},"source":["### Aspect F1 Score"]},{"cell_type":"code","metadata":{"id":"Nf2EzQvr2cKL","executionInfo":{"status":"ok","timestamp":1653841400266,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["def compute_aspect_f1_score(df_true, df_predicted):\n","  \"\"\"\n","  This function computest the macro F1 score of predicted aspects.\n","  0 => Represents that the aspect has not been detected by the model.\n","  1 => Represents that the aspect has been detected by the model.\n","  \"\"\"\n","\n","  df_true = df_true.replace([0, 1], 1).replace(2, 0)\n","  df_predicted = df_predicted.replace([0, 1], 1).replace(2, 0)\n","\n","  total_f1_score = 0\n","  total = 0\n","\n","  for i in range(df_true.shape[0]):\n","    true_values = list(df_true.iloc[i].values[2:])\n","    predicted_values = list(df_predicted.iloc[i].values[2:])\n","\n","    total_f1_score += f1_score(true_values, predicted_values, average=\"macro\")\n","    total += 1\n","\n","  score = float(total_f1_score)/float(total)*100\n","  return round(score, 2)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"1_4l9E3w3GhQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ac8f8233-ed27-47ae-f697-002c0d255614","executionInfo":{"status":"ok","timestamp":1653841402116,"user_tz":-420,"elapsed":1855,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["print(f\"Aspect F1 score: {compute_aspect_f1_score(df_true, df_predicted)}\")"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Aspect F1 score: 81.58\n"]}]},{"cell_type":"markdown","metadata":{"id":"yeKKnFqcgsqu"},"source":["# Prediction Result Analysis\n","\n","This section analyses the predicted results to find the aspects and sentiments that are most and least accurate. It utilizes the `df_true` and `df_predicted` dataframes constructed in the **Evaluation** section."]},{"cell_type":"code","metadata":{"id":"VaJU9DiRdtKL","executionInfo":{"status":"ok","timestamp":1653841406633,"user_tz":-420,"elapsed":4524,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["\"\"\"\n","Computes the positive_correct, positive_total, negative_correct, negative_total, \n","none_correct, none_total corresponding to all the aspects of LOCATION1 and \n","LOCATION2.\n","\"\"\"\n","\n","locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","df_location_aspect = pd.DataFrame({\"location\": [], \"aspect\": [], \"positive correct\": [], \"positive total\": [], \"negative correct\": [], \"negative total\": [], \"none correct\": [], \"none total\": [],})\n","\n","ii = 0\n","for location in locations:\n","  for aspect in aspects:\n","    positive_total = df_true[(df_true[aspect] == 0) & (df_true['location'] == location)].shape[0]\n","    negative_total = df_true[(df_true[aspect] == 1) & (df_true['location'] == location)].shape[0]\n","    none_total = df_true[(df_true[aspect] == 2) & (df_true['location'] == location)].shape[0]\n","\n","    positive_correct = 0\n","    for i in df_true[(df_true[aspect] == 0) & (df_true['location'] == location)].index:\n","      if df_predicted.iloc[i][aspect] == df_true.iloc[i][aspect]:\n","        positive_correct += 1\n","\n","    negative_correct = 0\n","    for i in df_true[(df_true[aspect] == 1) & (df_true['location'] == location)].index:\n","      if df_predicted.iloc[i][aspect] == df_true.iloc[i][aspect]:\n","        negative_correct += 1\n","\n","    none_correct = 0\n","    for i in df_true[(df_true[aspect] == 2) & (df_true['location'] == location)].index:\n","      if df_predicted.iloc[i][aspect] == df_true.iloc[i][aspect]:\n","        none_correct += 1\n","\n","    df_location_aspect.loc[ii] = [location, aspect, positive_correct, positive_total, negative_correct, negative_total, none_correct, none_total]\n","    ii += 1"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9PepIYSkl0X","executionInfo":{"status":"ok","timestamp":1653841406635,"user_tz":-420,"elapsed":21,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["df_location_aspect['positive percentage'] = round(df_location_aspect['positive correct']/df_location_aspect['positive total']*100, 2)\n","df_location_aspect['negative percentage'] = round(df_location_aspect['negative correct']/df_location_aspect['negative total']*100, 2)\n","df_location_aspect['none percentage'] = round(df_location_aspect['none correct']/df_location_aspect['none total']*100, 2)\n","\n","df_location_aspect['total percentage'] = round((df_location_aspect['positive correct'] + df_location_aspect['negative correct'] + df_location_aspect['none correct'])/(df_location_aspect['positive total'] + df_location_aspect['negative total'] + df_location_aspect['none total'])*100, 2)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"5qmq1AMSdtwv","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1653841406637,"user_tz":-420,"elapsed":20,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}},"outputId":"1e2b0a65-7690-481b-9a0d-f78ae1f73783"},"source":["df_location_aspect"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     location            aspect  positive correct  positive total  \\\n","0   LOCATION1            dining              31.0            31.0   \n","1   LOCATION1           general             319.0           359.0   \n","2   LOCATION1      green-nature              34.0            40.0   \n","3   LOCATION1              live              57.0            64.0   \n","4   LOCATION1     multicultural              36.0            39.0   \n","5   LOCATION1         nightlife              63.0            63.0   \n","6   LOCATION1             price              61.0            81.0   \n","7   LOCATION1             quiet              10.0            14.0   \n","8   LOCATION1            safety              57.0            61.0   \n","9   LOCATION1          shopping              61.0            62.0   \n","10  LOCATION1          touristy              19.0            25.0   \n","11  LOCATION1  transit-location             132.0           151.0   \n","12  LOCATION2            dining               4.0             4.0   \n","13  LOCATION2           general              67.0            88.0   \n","14  LOCATION2      green-nature               7.0             7.0   \n","15  LOCATION2              live              11.0            14.0   \n","16  LOCATION2     multicultural               8.0             8.0   \n","17  LOCATION2         nightlife              11.0            12.0   \n","18  LOCATION2             price              26.0            27.0   \n","19  LOCATION2             quiet               2.0             2.0   \n","20  LOCATION2            safety              14.0            14.0   \n","21  LOCATION2          shopping              15.0            15.0   \n","22  LOCATION2          touristy               5.0             5.0   \n","23  LOCATION2  transit-location              28.0            29.0   \n","\n","    negative correct  negative total  none correct  none total  \\\n","0                0.0             2.0        1441.0      1458.0   \n","1               91.0           113.0         729.0      1019.0   \n","2                0.0             0.0        1441.0      1451.0   \n","3               12.0            23.0        1323.0      1404.0   \n","4                1.0             3.0        1409.0      1449.0   \n","5                0.0             2.0        1346.0      1426.0   \n","6              104.0           116.0        1242.0      1294.0   \n","7                5.0            15.0        1456.0      1462.0   \n","8               47.0            66.0        1335.0      1364.0   \n","9                0.0             1.0        1382.0      1428.0   \n","10               0.0             0.0        1451.0      1466.0   \n","11              19.0            33.0        1173.0      1307.0   \n","12               0.0             0.0         377.0       384.0   \n","13              20.0            26.0         213.0       274.0   \n","14               0.0             0.0         376.0       381.0   \n","15               4.0             4.0         350.0       370.0   \n","16               1.0             1.0         371.0       379.0   \n","17               0.0             0.0         352.0       376.0   \n","18              27.0            27.0         318.0       334.0   \n","19               5.0             5.0         379.0       381.0   \n","20              17.0            17.0         344.0       357.0   \n","21               0.0             0.0         359.0       373.0   \n","22               0.0             0.0         373.0       383.0   \n","23               8.0             8.0         312.0       351.0   \n","\n","    positive percentage  negative percentage  none percentage  \\\n","0                100.00                 0.00            98.83   \n","1                 88.86                80.53            71.54   \n","2                 85.00                  NaN            99.31   \n","3                 89.06                52.17            94.23   \n","4                 92.31                33.33            97.24   \n","5                100.00                 0.00            94.39   \n","6                 75.31                89.66            95.98   \n","7                 71.43                33.33            99.59   \n","8                 93.44                71.21            97.87   \n","9                 98.39                 0.00            96.78   \n","10                76.00                  NaN            98.98   \n","11                87.42                57.58            89.75   \n","12               100.00                  NaN            98.18   \n","13                76.14                76.92            77.74   \n","14               100.00                  NaN            98.69   \n","15                78.57               100.00            94.59   \n","16               100.00               100.00            97.89   \n","17                91.67                  NaN            93.62   \n","18                96.30               100.00            95.21   \n","19               100.00               100.00            99.48   \n","20               100.00               100.00            96.36   \n","21               100.00                  NaN            96.25   \n","22               100.00                  NaN            97.39   \n","23                96.55               100.00            88.89   \n","\n","    total percentage  \n","0              98.73  \n","1              76.39  \n","2              98.93  \n","3              93.36  \n","4              96.98  \n","5              94.50  \n","6              94.37  \n","7              98.66  \n","8              96.51  \n","9              96.78  \n","10             98.59  \n","11             88.80  \n","12             98.20  \n","13             77.32  \n","14             98.71  \n","15             94.07  \n","16             97.94  \n","17             93.56  \n","18             95.62  \n","19             99.48  \n","20             96.65  \n","21             96.39  \n","22             97.42  \n","23             89.69  "],"text/html":["\n","  <div id=\"df-10684c58-15b8-4307-85c1-8469abed828f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>location</th>\n","      <th>aspect</th>\n","      <th>positive correct</th>\n","      <th>positive total</th>\n","      <th>negative correct</th>\n","      <th>negative total</th>\n","      <th>none correct</th>\n","      <th>none total</th>\n","      <th>positive percentage</th>\n","      <th>negative percentage</th>\n","      <th>none percentage</th>\n","      <th>total percentage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LOCATION1</td>\n","      <td>dining</td>\n","      <td>31.0</td>\n","      <td>31.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1441.0</td>\n","      <td>1458.0</td>\n","      <td>100.00</td>\n","      <td>0.00</td>\n","      <td>98.83</td>\n","      <td>98.73</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LOCATION1</td>\n","      <td>general</td>\n","      <td>319.0</td>\n","      <td>359.0</td>\n","      <td>91.0</td>\n","      <td>113.0</td>\n","      <td>729.0</td>\n","      <td>1019.0</td>\n","      <td>88.86</td>\n","      <td>80.53</td>\n","      <td>71.54</td>\n","      <td>76.39</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>LOCATION1</td>\n","      <td>green-nature</td>\n","      <td>34.0</td>\n","      <td>40.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1441.0</td>\n","      <td>1451.0</td>\n","      <td>85.00</td>\n","      <td>NaN</td>\n","      <td>99.31</td>\n","      <td>98.93</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LOCATION1</td>\n","      <td>live</td>\n","      <td>57.0</td>\n","      <td>64.0</td>\n","      <td>12.0</td>\n","      <td>23.0</td>\n","      <td>1323.0</td>\n","      <td>1404.0</td>\n","      <td>89.06</td>\n","      <td>52.17</td>\n","      <td>94.23</td>\n","      <td>93.36</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>LOCATION1</td>\n","      <td>multicultural</td>\n","      <td>36.0</td>\n","      <td>39.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1409.0</td>\n","      <td>1449.0</td>\n","      <td>92.31</td>\n","      <td>33.33</td>\n","      <td>97.24</td>\n","      <td>96.98</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>LOCATION1</td>\n","      <td>nightlife</td>\n","      <td>63.0</td>\n","      <td>63.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1346.0</td>\n","      <td>1426.0</td>\n","      <td>100.00</td>\n","      <td>0.00</td>\n","      <td>94.39</td>\n","      <td>94.50</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>LOCATION1</td>\n","      <td>price</td>\n","      <td>61.0</td>\n","      <td>81.0</td>\n","      <td>104.0</td>\n","      <td>116.0</td>\n","      <td>1242.0</td>\n","      <td>1294.0</td>\n","      <td>75.31</td>\n","      <td>89.66</td>\n","      <td>95.98</td>\n","      <td>94.37</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>LOCATION1</td>\n","      <td>quiet</td>\n","      <td>10.0</td>\n","      <td>14.0</td>\n","      <td>5.0</td>\n","      <td>15.0</td>\n","      <td>1456.0</td>\n","      <td>1462.0</td>\n","      <td>71.43</td>\n","      <td>33.33</td>\n","      <td>99.59</td>\n","      <td>98.66</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>LOCATION1</td>\n","      <td>safety</td>\n","      <td>57.0</td>\n","      <td>61.0</td>\n","      <td>47.0</td>\n","      <td>66.0</td>\n","      <td>1335.0</td>\n","      <td>1364.0</td>\n","      <td>93.44</td>\n","      <td>71.21</td>\n","      <td>97.87</td>\n","      <td>96.51</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>LOCATION1</td>\n","      <td>shopping</td>\n","      <td>61.0</td>\n","      <td>62.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1382.0</td>\n","      <td>1428.0</td>\n","      <td>98.39</td>\n","      <td>0.00</td>\n","      <td>96.78</td>\n","      <td>96.78</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>LOCATION1</td>\n","      <td>touristy</td>\n","      <td>19.0</td>\n","      <td>25.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1451.0</td>\n","      <td>1466.0</td>\n","      <td>76.00</td>\n","      <td>NaN</td>\n","      <td>98.98</td>\n","      <td>98.59</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>LOCATION1</td>\n","      <td>transit-location</td>\n","      <td>132.0</td>\n","      <td>151.0</td>\n","      <td>19.0</td>\n","      <td>33.0</td>\n","      <td>1173.0</td>\n","      <td>1307.0</td>\n","      <td>87.42</td>\n","      <td>57.58</td>\n","      <td>89.75</td>\n","      <td>88.80</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>LOCATION2</td>\n","      <td>dining</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>377.0</td>\n","      <td>384.0</td>\n","      <td>100.00</td>\n","      <td>NaN</td>\n","      <td>98.18</td>\n","      <td>98.20</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>LOCATION2</td>\n","      <td>general</td>\n","      <td>67.0</td>\n","      <td>88.0</td>\n","      <td>20.0</td>\n","      <td>26.0</td>\n","      <td>213.0</td>\n","      <td>274.0</td>\n","      <td>76.14</td>\n","      <td>76.92</td>\n","      <td>77.74</td>\n","      <td>77.32</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>LOCATION2</td>\n","      <td>green-nature</td>\n","      <td>7.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>376.0</td>\n","      <td>381.0</td>\n","      <td>100.00</td>\n","      <td>NaN</td>\n","      <td>98.69</td>\n","      <td>98.71</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>LOCATION2</td>\n","      <td>live</td>\n","      <td>11.0</td>\n","      <td>14.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>350.0</td>\n","      <td>370.0</td>\n","      <td>78.57</td>\n","      <td>100.00</td>\n","      <td>94.59</td>\n","      <td>94.07</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>LOCATION2</td>\n","      <td>multicultural</td>\n","      <td>8.0</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>371.0</td>\n","      <td>379.0</td>\n","      <td>100.00</td>\n","      <td>100.00</td>\n","      <td>97.89</td>\n","      <td>97.94</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>LOCATION2</td>\n","      <td>nightlife</td>\n","      <td>11.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>352.0</td>\n","      <td>376.0</td>\n","      <td>91.67</td>\n","      <td>NaN</td>\n","      <td>93.62</td>\n","      <td>93.56</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>LOCATION2</td>\n","      <td>price</td>\n","      <td>26.0</td>\n","      <td>27.0</td>\n","      <td>27.0</td>\n","      <td>27.0</td>\n","      <td>318.0</td>\n","      <td>334.0</td>\n","      <td>96.30</td>\n","      <td>100.00</td>\n","      <td>95.21</td>\n","      <td>95.62</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>LOCATION2</td>\n","      <td>quiet</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>379.0</td>\n","      <td>381.0</td>\n","      <td>100.00</td>\n","      <td>100.00</td>\n","      <td>99.48</td>\n","      <td>99.48</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>LOCATION2</td>\n","      <td>safety</td>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","      <td>17.0</td>\n","      <td>17.0</td>\n","      <td>344.0</td>\n","      <td>357.0</td>\n","      <td>100.00</td>\n","      <td>100.00</td>\n","      <td>96.36</td>\n","      <td>96.65</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>LOCATION2</td>\n","      <td>shopping</td>\n","      <td>15.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>359.0</td>\n","      <td>373.0</td>\n","      <td>100.00</td>\n","      <td>NaN</td>\n","      <td>96.25</td>\n","      <td>96.39</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>LOCATION2</td>\n","      <td>touristy</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>373.0</td>\n","      <td>383.0</td>\n","      <td>100.00</td>\n","      <td>NaN</td>\n","      <td>97.39</td>\n","      <td>97.42</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>LOCATION2</td>\n","      <td>transit-location</td>\n","      <td>28.0</td>\n","      <td>29.0</td>\n","      <td>8.0</td>\n","      <td>8.0</td>\n","      <td>312.0</td>\n","      <td>351.0</td>\n","      <td>96.55</td>\n","      <td>100.00</td>\n","      <td>88.89</td>\n","      <td>89.69</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10684c58-15b8-4307-85c1-8469abed828f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-10684c58-15b8-4307-85c1-8469abed828f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-10684c58-15b8-4307-85c1-8469abed828f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"HrFzIn4Jje3S"},"source":["# Creating preds.jsonl\n","\n","This section constructs the `preds.jsonl` file which contains model predictions and original annotations in the following json format.\n","\n","\n","```\n","{\n","  \"opinions\": [\n","    {\n","      \"sentiment\": \"Positive\",\n","      \"aspect\": \"safety\",\n","      \"target_entity\": \"LOCATION1\"\n","    }\n","  ],\n","  \"id\": 153,\n","  \"text\": \" LOCATION1 is in Greater London and is a very safe place\",\n","  \"model_pred\": [\n","    {\n","      \"sentiment\": ...,\n","      \"aspect\": ...,\n","      \"target_entity\":...\n","    },...\n","  ]\n","}\n","```"]},{"cell_type":"code","metadata":{"id":"Jx-1Q4Qmjrk6","executionInfo":{"status":"ok","timestamp":1653841407742,"user_tz":-420,"elapsed":1120,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["with open('/content/drive/MyDrive/BERT-ABSA/SentiHood Dataset/sentihood-test.json', 'r') as fp:\n","  testing_set = json.load(fp)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"8e97D5Osjtc2","executionInfo":{"status":"ok","timestamp":1653841407743,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["labels_to_sentiment_dict = {\n","    0: 'Positive',\n","    1: 'Negative',\n","    2: 'None'\n","}"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"BKvn4n6xl_WK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653841485425,"user_tz":-420,"elapsed":77686,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}},"outputId":"e78c708f-55dc-475a-a38f-ae5e6a2078a2"},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","\n","# models_dict:Is a dictionary containing models corresponding to all the \n","# `location-aspect`.\n","\n","models_dict = {}\n","\n","for location in locations:\n","  for aspect in tqdm(aspects, ncols=80):\n","    model = torch.load('/content/drive/MyDrive/BERT-ABSA/Bert-single/LocationAspectModels/'+str(location)+str(aspect)+'/0.bin')\n","    models_dict[f\"{location}{aspect}\"] = model"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████████| 12/12 [00:37<00:00,  3.09s/it]\n","100%|███████████████████████████████████████████| 12/12 [00:40<00:00,  3.39s/it]\n"]}]},{"cell_type":"code","metadata":{"id":"FVLiVoZ7kGbG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653841794237,"user_tz":-420,"elapsed":308818,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}},"outputId":"155d2021-8f0b-49a6-bc68-7dd8bb102071"},"source":["BERT_MODEL = 'bert-base-uncased'\n","MAX_LEN = 160\n","\n","tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Device: {device}\")\n","\n","for each_example in tqdm(testing_set, ncols=80):\n","  id = each_example['id']\n","  text = each_example['text'].strip()\n","\n","  each_example['model_pred'] = []\n","\n","  for location in locations:\n","    if location in text:\n","      # If \"location\" is present in the text, then utilize the trained models\n","      # to predict the aspects and their corresponding sentiment of the text.\n","\n","      for aspect in aspects:\n","        inputs = tokenizer.encode_plus(\n","            text,\n","            add_special_tokens = True,\n","            max_length = MAX_LEN,\n","            pad_to_max_length = True\n","        )\n","        ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).unsqueeze(0)\n","        mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).unsqueeze(0)\n","        token_type_ids = torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long).unsqueeze(0)\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","\n","        model = models_dict[f\"{location}{aspect}\"]\n","        outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        predicted = predicted.detach().cpu().numpy()\n","\n","        # If predicted sentiment is not None, then add it to the preds.jsonl.\n","\n","        if predicted[0] != 2:\n","          result = {\n","              \"sentiment\": labels_to_sentiment_dict[predicted[0]],\n","              \"aspect\": aspect,\n","              \"target_entity\": location\n","          }\n","          each_example['model_pred'].append(result)"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                  | 0/1491 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","100%|███████████████████████████████████████| 1491/1491 [05:07<00:00,  4.86it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"H7u0XKTadI6b","executionInfo":{"status":"ok","timestamp":1653841794237,"user_tz":-420,"elapsed":9,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":["with open('/content/drive/MyDrive/BERT-ABSA/Bert-single/preds.jsonl', mode='w', encoding='utf-8') as fp:\n","  for each in testing_set:\n","    json_record = json.dumps(each, ensure_ascii=False)\n","    fp.write(json_record + '\\n')"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"5e9qfGJy1roG","executionInfo":{"status":"ok","timestamp":1653841794238,"user_tz":-420,"elapsed":8,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"08847744919763405838"}}},"source":[""],"execution_count":27,"outputs":[]}]}