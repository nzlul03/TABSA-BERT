{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Inference and Evaluation of BERT-pair NLI-M.ipynb","provenance":[],"collapsed_sections":["LACVADTH_U8N","qG4vUkDMGtZ6","HzING8oSa24-","hHUu0aX4poUu"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2e6d743a1d624ad89a319c8f7ec6695a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5535f53ba6e4158847d91bbfd76f412","IPY_MODEL_56bdede148e446b48a41749029579fb2","IPY_MODEL_9557ddcd7f274cda92a4cf2651a1901d"],"layout":"IPY_MODEL_97477327e5e34305887010d649b0b103"}},"a5535f53ba6e4158847d91bbfd76f412":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f079ff6e230642b3a06ab6bd89f12228","placeholder":"​","style":"IPY_MODEL_8c6c8751faec4b5e829fcc4eed406848","value":"Downloading: 100%"}},"56bdede148e446b48a41749029579fb2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_26b65e1a10bf455ba2922e70c01b6f82","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15e8b92ecb10478881239ed18e2881d7","value":231508}},"9557ddcd7f274cda92a4cf2651a1901d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b442e0881224f878129f1d916ab289d","placeholder":"​","style":"IPY_MODEL_6d3cfd676ffc4fb69ef5508ffa444bfc","value":" 226k/226k [00:00&lt;00:00, 1.49MB/s]"}},"97477327e5e34305887010d649b0b103":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f079ff6e230642b3a06ab6bd89f12228":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c6c8751faec4b5e829fcc4eed406848":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26b65e1a10bf455ba2922e70c01b6f82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15e8b92ecb10478881239ed18e2881d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b442e0881224f878129f1d916ab289d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d3cfd676ffc4fb69ef5508ffa444bfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc332892afb6470f8c37fb7d6b128884":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c62b096e81449b99fd65d7ce78def10","IPY_MODEL_d586a1297afd46d38b2591cdc28e85c7","IPY_MODEL_1114ae365ebf4db683969502be28abc4"],"layout":"IPY_MODEL_0cde585d4edc4906b72d6c4b5f0c2c86"}},"5c62b096e81449b99fd65d7ce78def10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84b2983938ee41cd8ab7125bc6060ac4","placeholder":"​","style":"IPY_MODEL_1ff1b919b4ee4ec9b24a1f6c4e05416f","value":"Downloading: 100%"}},"d586a1297afd46d38b2591cdc28e85c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e859434ae1649b18a9420221ca13532","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f97b1307a664ba09925c749b2c33439","value":28}},"1114ae365ebf4db683969502be28abc4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7171d9be8c4143fbb111a11615ea8fdd","placeholder":"​","style":"IPY_MODEL_c1134b1ad1514c50a83b3dd043409575","value":" 28.0/28.0 [00:00&lt;00:00, 623B/s]"}},"0cde585d4edc4906b72d6c4b5f0c2c86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84b2983938ee41cd8ab7125bc6060ac4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ff1b919b4ee4ec9b24a1f6c4e05416f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e859434ae1649b18a9420221ca13532":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f97b1307a664ba09925c749b2c33439":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7171d9be8c4143fbb111a11615ea8fdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1134b1ad1514c50a83b3dd043409575":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c86e43c2e9844c2f8173483567a92037":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52bde282eb6145c0a051d353e951cd1b","IPY_MODEL_26ef83d156af4f11add279f4eee1ba72","IPY_MODEL_da81d72f28fd46b08359744cfa168e52"],"layout":"IPY_MODEL_ada31cf6c60b4abaaf11cebec354b0d7"}},"52bde282eb6145c0a051d353e951cd1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e431c6cc14cc4f3eb39086c8cffc17bf","placeholder":"​","style":"IPY_MODEL_5bd3a263c1e64c0caa047440e42d5228","value":"Downloading: 100%"}},"26ef83d156af4f11add279f4eee1ba72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4edbb3777f5742de84edd8385ab9156f","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e7c528436a414a38b98f81319fd0b32c","value":570}},"da81d72f28fd46b08359744cfa168e52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a14c094160d4895900cbe9d2bdad9ed","placeholder":"​","style":"IPY_MODEL_526aa3a86ea1436fab04d3188e768d31","value":" 570/570 [00:00&lt;00:00, 16.6kB/s]"}},"ada31cf6c60b4abaaf11cebec354b0d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e431c6cc14cc4f3eb39086c8cffc17bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bd3a263c1e64c0caa047440e42d5228":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4edbb3777f5742de84edd8385ab9156f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7c528436a414a38b98f81319fd0b32c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a14c094160d4895900cbe9d2bdad9ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"526aa3a86ea1436fab04d3188e768d31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"id":"hIANK2Rn_AS2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653617602295,"user_tz":-420,"elapsed":8665,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"3f75c19d-274b-42d2-a6a3-0cd6a70ddfd1"},"source":["# Install dependencies\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 5.0 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 54.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.2 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 13.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"]}]},{"cell_type":"code","metadata":{"id":"0uIEvh0A_FUk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653617620308,"user_tz":-420,"elapsed":18035,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"ef099dac-c04d-4e20-9ff8-6aca6dcef7c7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VK9hehrGkV8h","executionInfo":{"status":"ok","timestamp":1653617620835,"user_tz":-420,"elapsed":542,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"6ba88093-bd92-41cf-f8a4-ccaf68ae9dbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M\n"]}]},{"cell_type":"code","metadata":{"id":"GK_-dM26_TGi"},"source":["import json\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import numpy as np\n","import transformers\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, accuracy_score\n","from transformers import BertModel, BertTokenizer\n","\n","import logging\n","logging.basicConfig(level=logging.ERROR)\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VGTic4EP_XSG"},"source":["class SentimentClassifier(nn.Module):\n","  \"\"\"\n","  This class defines the model architecture which is simply a fully-connected\n","  layer on top of a pre-trained BERT model. \n","  \"\"\"\n","\n","  def __init__(self, BERT_MODEL):\n","    super(SentimentClassifier, self).__init__()\n","    self.bert = BertModel.from_pretrained(BERT_MODEL)\n","    self.drop = nn.Dropout(p=0.3)\n","    self.out = nn.Linear(self.bert.config.hidden_size, 3)\n","    # Number of output classes = 3\n","\n","  def forward(self, ids, mask, token_type_ids):\n","    last_hidden_state, pooled_output = self.bert(ids, attention_mask=mask,\n","                                                 token_type_ids=token_type_ids,\n","                                                 return_dict=False)\n","    output = self.drop(pooled_output)\n","    return self.out(output)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LACVADTH_U8N"},"source":["# Inference on BERT-pair NLI-M"]},{"cell_type":"code","metadata":{"id":"hDO650jp_Z7X"},"source":["class SentiHood:\n","  \"\"\"\n","  This class tokenizes the input text using the pre-trained BERT tokenizer \n","  (wordpiece) and returns the corresponding tensors.\n","  \"\"\"\n","  \n","  def __init__(self, opinions_id, text, auxiliary_sentence, targets, tokenizer, max_len):\n","    self.opinions_id = opinions_id\n","    self.text = text\n","    self.auxiliary_sentence = auxiliary_sentence\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","    self.targets = targets\n","\n","  def __len__(self):\n","    return len(self.targets)\n","\n","  def __getitem__(self, item):\n","    opinions_id = self.opinions_id[item]\n","    text = str(self.text[item])\n","    auxiliary_sentence = str(self.auxiliary_sentence[item])\n","    targets = self.targets[item]\n","\n","    text = text + ' ' + auxiliary_sentence\n","\n","    inputs = self.tokenizer.encode_plus(\n","        text,\n","        add_special_tokens = True,\n","        max_length = self.max_len,\n","        pad_to_max_length = True\n","    )\n","\n","    ids = inputs[\"input_ids\"]\n","    mask = inputs[\"attention_mask\"]\n","    token_type_ids = inputs[\"token_type_ids\"]\n","\n","    return {\n","        \"ids\": torch.tensor(ids, dtype=torch.long),\n","        \"mask\": torch.tensor(mask, dtype=torch.long),\n","        \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n","        \"targets\": torch.tensor(targets, dtype=torch.long),\n","        \"opinions_id\": torch.tensor(opinions_id, dtype=torch.long)\n","    }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tc_tUUJABEVB"},"source":["def infer_loop_function(data_loader, model, device):\n","  \"\"\"\n","  This function performs the inference on testing sets and stores the predicted\n","  values.\n","  \"\"\"\n","\n","  model.eval()\n","\n","  df_pred = pd.DataFrame({\"id\": [], \"predicted\": [], \"actual\": []})\n","\n","  ii = 0\n","  for bi, d in tqdm(enumerate(data_loader), total=len(data_loader), ncols=80):\n","    opinions_id = d[\"opinions_id\"]\n","    ids = d[\"ids\"]\n","    mask = d[\"mask\"]\n","    token_type_ids = d[\"token_type_ids\"]\n","    targets = d[\"targets\"]\n","\n","    opinions_id = opinions_id.to(device, dtype=torch.long)\n","    ids = ids.to(device, dtype=torch.long)\n","    mask = mask.to(device, dtype=torch.long)\n","    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","    targets = targets.to(device, dtype=torch.long)\n","\n","    outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n","    _, predicted = torch.max(outputs, 1)\n","    \n","    predicted = predicted.detach().cpu().numpy()\n","    targets = targets.detach().cpu().numpy()\n","    opinions_id = opinions_id.detach().cpu().numpy()\n","\n","    for k in range(len(predicted)):\n","      df_pred.loc[ii] = [str(opinions_id[k]), str(predicted[k]), str(targets[k])]\n","      ii += 1\n","\n","    df_pred.to_csv('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M/PredictedValues.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xalt3-vB_doq","colab":{"base_uri":"https://localhost:8080/","height":206,"referenced_widgets":["2e6d743a1d624ad89a319c8f7ec6695a","a5535f53ba6e4158847d91bbfd76f412","56bdede148e446b48a41749029579fb2","9557ddcd7f274cda92a4cf2651a1901d","97477327e5e34305887010d649b0b103","f079ff6e230642b3a06ab6bd89f12228","8c6c8751faec4b5e829fcc4eed406848","26b65e1a10bf455ba2922e70c01b6f82","15e8b92ecb10478881239ed18e2881d7","9b442e0881224f878129f1d916ab289d","6d3cfd676ffc4fb69ef5508ffa444bfc","cc332892afb6470f8c37fb7d6b128884","5c62b096e81449b99fd65d7ce78def10","d586a1297afd46d38b2591cdc28e85c7","1114ae365ebf4db683969502be28abc4","0cde585d4edc4906b72d6c4b5f0c2c86","84b2983938ee41cd8ab7125bc6060ac4","1ff1b919b4ee4ec9b24a1f6c4e05416f","0e859434ae1649b18a9420221ca13532","8f97b1307a664ba09925c749b2c33439","7171d9be8c4143fbb111a11615ea8fdd","c1134b1ad1514c50a83b3dd043409575","c86e43c2e9844c2f8173483567a92037","52bde282eb6145c0a051d353e951cd1b","26ef83d156af4f11add279f4eee1ba72","da81d72f28fd46b08359744cfa168e52","ada31cf6c60b4abaaf11cebec354b0d7","e431c6cc14cc4f3eb39086c8cffc17bf","5bd3a263c1e64c0caa047440e42d5228","4edbb3777f5742de84edd8385ab9156f","e7c528436a414a38b98f81319fd0b32c","9a14c094160d4895900cbe9d2bdad9ed","526aa3a86ea1436fab04d3188e768d31"]},"outputId":"90205ed0-34d5-438b-eb61-f79c6e3a1237","executionInfo":{"status":"ok","timestamp":1653617900690,"user_tz":-420,"elapsed":227041,"user":{"displayName":"project colab","userId":"14559293068416285175"}}},"source":["def run():\n","  \"\"\"\n","  This function defines the necessary hyperparameters and models. It also \n","  loads and tokenizes the testing dataset and execute the inference procedure.\n","  \"\"\"\n","\n","  TRAIN_MAX_LEN = 160\n","  TRAIN_BATCH_SIZE = 24\n","  BERT_MODEL = 'bert-base-uncased'\n","\n","  testing_set_path = '/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M/Datasets/testing_set.csv'\n","\n","  df_test = pd.read_csv(testing_set_path)\n","  sentiment_mapping = {\n","      'Positive': 0,\n","      'Negative': 1,\n","      'None': 2\n","  }\n","  df_test['sentiment'] = df_test['sentiment'].map(sentiment_mapping)\n","  df_test = df_test.reset_index(drop=True)\n","\n","  tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n","\n","  test_dataset = SentiHood(\n","      opinions_id = df_test['id'].values,\n","      text = df_test['text'].values,\n","      auxiliary_sentence = df_test['auxiliary_sentence'],\n","      targets = df_test['sentiment'].values,\n","      tokenizer = tokenizer,\n","      max_len = TRAIN_MAX_LEN\n","  )\n","  print(f\"Training Set: {len(test_dataset)}\")\n","\n","  test_data_loader = torch.utils.data.DataLoader(\n","      test_dataset,\n","      batch_size = TRAIN_BATCH_SIZE,\n","      shuffle=False\n","  )\n","\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  print(f\"Device: {device}\")\n","\n","  model = torch.load('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M/Models/3.bin')\n","  infer_loop_function(data_loader=test_data_loader, model=model, device=device)\n","      \n","if __name__ == \"__main__\":\n","  run()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e6d743a1d624ad89a319c8f7ec6695a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc332892afb6470f8c37fb7d6b128884"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c86e43c2e9844c2f8173483567a92037"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training Set: 22548\n","Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                   | 0/940 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","100%|█████████████████████████████████████████| 940/940 [03:21<00:00,  4.67it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"qG4vUkDMGtZ6"},"source":["# Evaluation of BERT-pair NLI-M"]},{"cell_type":"code","metadata":{"id":"HtYO_f4pGyJY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653618051612,"user_tz":-420,"elapsed":311,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"1f56fe8e-3739-4859-cfe6-479d08d6b86d"},"source":["def compute_sentiment_accuracy(df):\n","  \"\"\"This function computes the sentiment classfication accuracy\"\"\"\n","  \n","  accuracy = df[df['predicted'] == df['actual']].shape[0]/df.shape[0] * 100\n","  return round(accuracy, 2)\n","\n","df = pd.read_csv('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M/PredictedValues.csv')\n","print(f'Sentiment Accuracy of BERT-pair NLI-M = {compute_sentiment_accuracy(df)}%')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment Accuracy of BERT-pair NLI-M = 96.57%\n"]}]},{"cell_type":"code","metadata":{"id":"icSi6UoPHLAG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653618098610,"user_tz":-420,"elapsed":812,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"bfbf072b-834c-41ac-948f-f75f5cff37c3"},"source":["def compute_aspect_accuracy(df):\n","  \"\"\"\n","  This function computes the strict aspect accuracy.\n","  0 => Represents that the aspect has not been detected.\n","  1 => Represents that the aspect has been detected.\n","  \"\"\"\n","  \n","  df = df.replace([0, 1], 1).replace(2, 0)\n","\n","  count = 0\n","  total = 0\n","\n","  for i in range(0, df.shape[0], 12):\n","    true_values = df.iloc[i:i+12]['predicted']\n","    predicted_values = df.iloc[i:i+12]['actual']\n","\n","    if (true_values == predicted_values).all():\n","      count += 1\n","    total += 1\n","\n","  accuracy = float(count)/float(total)*100\n","  return round(accuracy, 2)\n","\n","df = pd.read_csv('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M/PredictedValues.csv')\n","print(f'Aspect Accuracy (strict) of BERT-pair NLI-M = {compute_aspect_accuracy(df)}%')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Aspect Accuracy (strict) of BERT-pair NLI-M = 69.72%\n"]}]},{"cell_type":"code","metadata":{"id":"TzIfR5nxKbv9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653618119163,"user_tz":-420,"elapsed":1942,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"3175c85c-3922-43eb-85fc-057394f9c097"},"source":["def compute_aspect_f1_score(df):\n","  \"\"\"\n","  This function computest the macro F1 score of predicted aspects.\n","  0 => Represents that the aspect has not been detected.\n","  1 => Represents that the aspect has been detected.\n","  \"\"\"\n","  \n","  df = df.replace([0, 1], 1).replace(2, 0)\n","\n","  total_f1_score = 0\n","  total = 0\n","  \n","  for i in range(0, df.shape[0], 12):\n","    true_values = df.iloc[i:i+12]['predicted']\n","    predicted_values = df.iloc[i:i+12]['actual']\n","\n","    total_f1_score += f1_score(true_values, predicted_values, average=\"macro\")\n","    total += 1\n","\n","  score = float(total_f1_score)/float(total)*100\n","  return round(score, 2)\n","\n","df = pd.read_csv('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M/PredictedValues.csv')\n","print(f\"Aspect F1 score: {compute_aspect_f1_score(df)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Aspect F1 score: 89.53\n"]}]},{"cell_type":"markdown","metadata":{"id":"HzING8oSa24-"},"source":["# Prediction Result Analysis\n","\n","This section analyses the predicted results to find the aspects and sentiments that are most and least accurate.\n","\n","*Note*: Utilizing the fact that first 1491x12 entries in the loaded `df` are related to `location-1` and rest are related to `location-2`. "]},{"cell_type":"code","metadata":{"id":"TlZzdPaEa7kG"},"source":["df = pd.read_csv('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M/PredictedValues.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_FUCBuda7nM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653618146899,"user_tz":-420,"elapsed":5322,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"42160afb-9525-4b64-bc28-5ee209d9ccfc"},"source":["\"\"\"\n","Computes the positive correct, positive total, negative correct, negative total, \n","none correct, none total corresponding to all the aspects of LOCATION1.\n","\"\"\"\n","\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife',\n","           'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","location1_aspects_result_analysis = {}\n","\n","for i in range(12):\n","  location1_aspects_result_analysis[aspects[i]] = [[0 ,0], [0 ,0], [0 ,0]]\n","\n","for i in tqdm(range(0, df['id'].unique().shape[0]*12-12, 12), ncols=80):\n","  for j in range(12):\n","    if df.loc[i+j]['actual'] == df.loc[i+j]['predicted']:\n","      location1_aspects_result_analysis[aspects[j]][int(df.loc[i+j]['actual'])][0] += 1\n","    \n","    location1_aspects_result_analysis[aspects[j]][int(df.loc[i+j]['actual'])][1] += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████| 1490/1490 [00:05<00:00, 282.01it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"DHIz2mkva7hK"},"source":["df_location_aspect = pd.DataFrame({\"location\": [], \"aspect\": [], \"positive correct\": [],\n","                                   \"positive total\": [], \"negative correct\": [],\n","                                   \"negative total\": [], \"none correct\": [], \"none total\": [],})\n","\n","ii = 0\n","for key in location1_aspects_result_analysis.keys():\n","  df_location_aspect.loc[ii] = ['LOCATION1', f\"{key}\", \n","                                location1_aspects_result_analysis[key][0][0], \n","                                location1_aspects_result_analysis[key][0][1], \n","                                location1_aspects_result_analysis[key][1][0], \n","                                location1_aspects_result_analysis[key][1][1], \n","                                location1_aspects_result_analysis[key][2][0], \n","                                location1_aspects_result_analysis[key][2][1]]\n","  ii += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iwOBj9eAbg7r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653618150170,"user_tz":-420,"elapsed":1823,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"82b62148-4d0c-4f0f-b7d1-3c4ac38b055c"},"source":["\"\"\"\n","Computes the positive correct, positive total, negative correct, negative total, \n","none correct, none total corresponding to all the aspects of LOCATION2.\n","\"\"\"\n","\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife',\n","           'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","location2_aspects_result_analysis = {}\n","\n","for i in range(12):\n","  location2_aspects_result_analysis[aspects[i]] = [[0 ,0], [0 ,0], [0 ,0]]\n","\n","for i in tqdm(range(df['id'].unique().shape[0]*12, df.shape[0]-12, 12), ncols=80):\n","  for j in range(12):\n","    if df.loc[i+j]['actual'] == df.loc[i+j]['predicted']:\n","      location2_aspects_result_analysis[aspects[j]][int(df.loc[i+j]['actual'])][0] += 1\n","    \n","    location2_aspects_result_analysis[aspects[j]][int(df.loc[i+j]['actual'])][1] += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|████████████████████████████████████████| 387/387 [00:01<00:00, 282.41it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"JqOK-qB5bg40"},"source":["for key in location2_aspects_result_analysis.keys():\n","  df_location_aspect.loc[ii] = ['LOCATION2', f\"{key}\", \n","                                location2_aspects_result_analysis[key][0][0], \n","                                location2_aspects_result_analysis[key][0][1], \n","                                location2_aspects_result_analysis[key][1][0], \n","                                location2_aspects_result_analysis[key][1][1], \n","                                location2_aspects_result_analysis[key][2][0], \n","                                location2_aspects_result_analysis[key][2][1]]\n","  ii += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VOy4F1tnbg2k"},"source":["df_location_aspect['positive percentage'] = round(df_location_aspect['positive correct']/df_location_aspect['positive total']*100, 2)\n","df_location_aspect['negative percentage'] = round(df_location_aspect['negative correct']/df_location_aspect['negative total']*100, 2)\n","df_location_aspect['none percentage'] = round(df_location_aspect['none correct']/df_location_aspect['none total']*100, 2)\n","\n","df_location_aspect['total percentage'] = round((df_location_aspect['positive correct'] + df_location_aspect['negative correct'] + df_location_aspect['none correct'])/(df_location_aspect['positive total'] + df_location_aspect['negative total'] + df_location_aspect['none total'])*100, 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nXssXWzMbqtq","colab":{"base_uri":"https://localhost:8080/","height":952},"executionInfo":{"status":"ok","timestamp":1653618157244,"user_tz":-420,"elapsed":295,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"951e59c4-cd43-4ba1-c9c5-d3d08a5933a1"},"source":["df_location_aspect"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     location            aspect  positive correct  positive total  \\\n","0   LOCATION1            dining              30.0            30.0   \n","1   LOCATION1           general             311.0           359.0   \n","2   LOCATION1      green-nature              35.0            40.0   \n","3   LOCATION1              live              52.0            63.0   \n","4   LOCATION1     multicultural              34.0            39.0   \n","5   LOCATION1         nightlife              59.0            62.0   \n","6   LOCATION1             price              70.0            81.0   \n","7   LOCATION1             quiet              13.0            14.0   \n","8   LOCATION1            safety              55.0            61.0   \n","9   LOCATION1          shopping              62.0            62.0   \n","10  LOCATION1          touristy              20.0            25.0   \n","11  LOCATION1  transit-location             137.0           151.0   \n","12  LOCATION2            dining               4.0             4.0   \n","13  LOCATION2           general              73.0            87.0   \n","14  LOCATION2      green-nature               6.0             7.0   \n","15  LOCATION2              live              14.0            14.0   \n","16  LOCATION2     multicultural               6.0             8.0   \n","17  LOCATION2         nightlife              12.0            12.0   \n","18  LOCATION2             price              22.0            27.0   \n","19  LOCATION2             quiet               1.0             2.0   \n","20  LOCATION2            safety              12.0            14.0   \n","21  LOCATION2          shopping              15.0            15.0   \n","22  LOCATION2          touristy               4.0             5.0   \n","23  LOCATION2  transit-location              25.0            29.0   \n","\n","    negative correct  negative total  none correct  none total  \\\n","0                0.0             2.0        1449.0      1458.0   \n","1               91.0           113.0         920.0      1018.0   \n","2                0.0             0.0        1440.0      1450.0   \n","3               19.0            23.0        1334.0      1404.0   \n","4                3.0             3.0        1437.0      1448.0   \n","5                1.0             2.0        1402.0      1426.0   \n","6              110.0           116.0        1250.0      1293.0   \n","7               13.0            15.0        1456.0      1461.0   \n","8               56.0            66.0        1332.0      1363.0   \n","9                1.0             1.0        1410.0      1427.0   \n","10               0.0             0.0        1449.0      1465.0   \n","11              22.0            33.0        1209.0      1306.0   \n","12               0.0             0.0         377.0       383.0   \n","13              18.0            26.0         244.0       274.0   \n","14               0.0             0.0         377.0       380.0   \n","15               3.0             4.0         356.0       369.0   \n","16               1.0             1.0         375.0       378.0   \n","17               0.0             0.0         371.0       375.0   \n","18              25.0            27.0         313.0       333.0   \n","19               3.0             5.0         379.0       380.0   \n","20              12.0            17.0         350.0       356.0   \n","21               0.0             0.0         370.0       372.0   \n","22               0.0             0.0         380.0       382.0   \n","23               6.0             8.0         315.0       350.0   \n","\n","    positive percentage  negative percentage  none percentage  \\\n","0                100.00                 0.00            99.38   \n","1                 86.63                80.53            90.37   \n","2                 87.50                  NaN            99.31   \n","3                 82.54                82.61            95.01   \n","4                 87.18               100.00            99.24   \n","5                 95.16                50.00            98.32   \n","6                 86.42                94.83            96.67   \n","7                 92.86                86.67            99.66   \n","8                 90.16                84.85            97.73   \n","9                100.00               100.00            98.81   \n","10                80.00                  NaN            98.91   \n","11                90.73                66.67            92.57   \n","12               100.00                  NaN            98.43   \n","13                83.91                69.23            89.05   \n","14                85.71                  NaN            99.21   \n","15               100.00                75.00            96.48   \n","16                75.00               100.00            99.21   \n","17               100.00                  NaN            98.93   \n","18                81.48                92.59            93.99   \n","19                50.00                60.00            99.74   \n","20                85.71                70.59            98.31   \n","21               100.00                  NaN            99.46   \n","22                80.00                  NaN            99.48   \n","23                86.21                75.00            90.00   \n","\n","    total percentage  \n","0              99.26  \n","1              88.72  \n","2              98.99  \n","3              94.30  \n","4              98.93  \n","5              98.12  \n","6              95.97  \n","7              99.46  \n","8              96.85  \n","9              98.86  \n","10             98.59  \n","11             91.81  \n","12             98.45  \n","13             86.56  \n","14             98.97  \n","15             96.38  \n","16             98.71  \n","17             98.97  \n","18             93.02  \n","19             98.97  \n","20             96.64  \n","21             99.48  \n","22             99.22  \n","23             89.41  "],"text/html":["\n","  <div id=\"df-b2328776-fe07-4766-a2e2-f4aee11494be\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>location</th>\n","      <th>aspect</th>\n","      <th>positive correct</th>\n","      <th>positive total</th>\n","      <th>negative correct</th>\n","      <th>negative total</th>\n","      <th>none correct</th>\n","      <th>none total</th>\n","      <th>positive percentage</th>\n","      <th>negative percentage</th>\n","      <th>none percentage</th>\n","      <th>total percentage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LOCATION1</td>\n","      <td>dining</td>\n","      <td>30.0</td>\n","      <td>30.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1449.0</td>\n","      <td>1458.0</td>\n","      <td>100.00</td>\n","      <td>0.00</td>\n","      <td>99.38</td>\n","      <td>99.26</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LOCATION1</td>\n","      <td>general</td>\n","      <td>311.0</td>\n","      <td>359.0</td>\n","      <td>91.0</td>\n","      <td>113.0</td>\n","      <td>920.0</td>\n","      <td>1018.0</td>\n","      <td>86.63</td>\n","      <td>80.53</td>\n","      <td>90.37</td>\n","      <td>88.72</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>LOCATION1</td>\n","      <td>green-nature</td>\n","      <td>35.0</td>\n","      <td>40.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1440.0</td>\n","      <td>1450.0</td>\n","      <td>87.50</td>\n","      <td>NaN</td>\n","      <td>99.31</td>\n","      <td>98.99</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LOCATION1</td>\n","      <td>live</td>\n","      <td>52.0</td>\n","      <td>63.0</td>\n","      <td>19.0</td>\n","      <td>23.0</td>\n","      <td>1334.0</td>\n","      <td>1404.0</td>\n","      <td>82.54</td>\n","      <td>82.61</td>\n","      <td>95.01</td>\n","      <td>94.30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>LOCATION1</td>\n","      <td>multicultural</td>\n","      <td>34.0</td>\n","      <td>39.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>1437.0</td>\n","      <td>1448.0</td>\n","      <td>87.18</td>\n","      <td>100.00</td>\n","      <td>99.24</td>\n","      <td>98.93</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>LOCATION1</td>\n","      <td>nightlife</td>\n","      <td>59.0</td>\n","      <td>62.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1402.0</td>\n","      <td>1426.0</td>\n","      <td>95.16</td>\n","      <td>50.00</td>\n","      <td>98.32</td>\n","      <td>98.12</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>LOCATION1</td>\n","      <td>price</td>\n","      <td>70.0</td>\n","      <td>81.0</td>\n","      <td>110.0</td>\n","      <td>116.0</td>\n","      <td>1250.0</td>\n","      <td>1293.0</td>\n","      <td>86.42</td>\n","      <td>94.83</td>\n","      <td>96.67</td>\n","      <td>95.97</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>LOCATION1</td>\n","      <td>quiet</td>\n","      <td>13.0</td>\n","      <td>14.0</td>\n","      <td>13.0</td>\n","      <td>15.0</td>\n","      <td>1456.0</td>\n","      <td>1461.0</td>\n","      <td>92.86</td>\n","      <td>86.67</td>\n","      <td>99.66</td>\n","      <td>99.46</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>LOCATION1</td>\n","      <td>safety</td>\n","      <td>55.0</td>\n","      <td>61.0</td>\n","      <td>56.0</td>\n","      <td>66.0</td>\n","      <td>1332.0</td>\n","      <td>1363.0</td>\n","      <td>90.16</td>\n","      <td>84.85</td>\n","      <td>97.73</td>\n","      <td>96.85</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>LOCATION1</td>\n","      <td>shopping</td>\n","      <td>62.0</td>\n","      <td>62.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1410.0</td>\n","      <td>1427.0</td>\n","      <td>100.00</td>\n","      <td>100.00</td>\n","      <td>98.81</td>\n","      <td>98.86</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>LOCATION1</td>\n","      <td>touristy</td>\n","      <td>20.0</td>\n","      <td>25.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1449.0</td>\n","      <td>1465.0</td>\n","      <td>80.00</td>\n","      <td>NaN</td>\n","      <td>98.91</td>\n","      <td>98.59</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>LOCATION1</td>\n","      <td>transit-location</td>\n","      <td>137.0</td>\n","      <td>151.0</td>\n","      <td>22.0</td>\n","      <td>33.0</td>\n","      <td>1209.0</td>\n","      <td>1306.0</td>\n","      <td>90.73</td>\n","      <td>66.67</td>\n","      <td>92.57</td>\n","      <td>91.81</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>LOCATION2</td>\n","      <td>dining</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>377.0</td>\n","      <td>383.0</td>\n","      <td>100.00</td>\n","      <td>NaN</td>\n","      <td>98.43</td>\n","      <td>98.45</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>LOCATION2</td>\n","      <td>general</td>\n","      <td>73.0</td>\n","      <td>87.0</td>\n","      <td>18.0</td>\n","      <td>26.0</td>\n","      <td>244.0</td>\n","      <td>274.0</td>\n","      <td>83.91</td>\n","      <td>69.23</td>\n","      <td>89.05</td>\n","      <td>86.56</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>LOCATION2</td>\n","      <td>green-nature</td>\n","      <td>6.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>377.0</td>\n","      <td>380.0</td>\n","      <td>85.71</td>\n","      <td>NaN</td>\n","      <td>99.21</td>\n","      <td>98.97</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>LOCATION2</td>\n","      <td>live</td>\n","      <td>14.0</td>\n","      <td>14.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>356.0</td>\n","      <td>369.0</td>\n","      <td>100.00</td>\n","      <td>75.00</td>\n","      <td>96.48</td>\n","      <td>96.38</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>LOCATION2</td>\n","      <td>multicultural</td>\n","      <td>6.0</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>375.0</td>\n","      <td>378.0</td>\n","      <td>75.00</td>\n","      <td>100.00</td>\n","      <td>99.21</td>\n","      <td>98.71</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>LOCATION2</td>\n","      <td>nightlife</td>\n","      <td>12.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>371.0</td>\n","      <td>375.0</td>\n","      <td>100.00</td>\n","      <td>NaN</td>\n","      <td>98.93</td>\n","      <td>98.97</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>LOCATION2</td>\n","      <td>price</td>\n","      <td>22.0</td>\n","      <td>27.0</td>\n","      <td>25.0</td>\n","      <td>27.0</td>\n","      <td>313.0</td>\n","      <td>333.0</td>\n","      <td>81.48</td>\n","      <td>92.59</td>\n","      <td>93.99</td>\n","      <td>93.02</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>LOCATION2</td>\n","      <td>quiet</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>379.0</td>\n","      <td>380.0</td>\n","      <td>50.00</td>\n","      <td>60.00</td>\n","      <td>99.74</td>\n","      <td>98.97</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>LOCATION2</td>\n","      <td>safety</td>\n","      <td>12.0</td>\n","      <td>14.0</td>\n","      <td>12.0</td>\n","      <td>17.0</td>\n","      <td>350.0</td>\n","      <td>356.0</td>\n","      <td>85.71</td>\n","      <td>70.59</td>\n","      <td>98.31</td>\n","      <td>96.64</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>LOCATION2</td>\n","      <td>shopping</td>\n","      <td>15.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>370.0</td>\n","      <td>372.0</td>\n","      <td>100.00</td>\n","      <td>NaN</td>\n","      <td>99.46</td>\n","      <td>99.48</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>LOCATION2</td>\n","      <td>touristy</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>380.0</td>\n","      <td>382.0</td>\n","      <td>80.00</td>\n","      <td>NaN</td>\n","      <td>99.48</td>\n","      <td>99.22</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>LOCATION2</td>\n","      <td>transit-location</td>\n","      <td>25.0</td>\n","      <td>29.0</td>\n","      <td>6.0</td>\n","      <td>8.0</td>\n","      <td>315.0</td>\n","      <td>350.0</td>\n","      <td>86.21</td>\n","      <td>75.00</td>\n","      <td>90.00</td>\n","      <td>89.41</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2328776-fe07-4766-a2e2-f4aee11494be')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b2328776-fe07-4766-a2e2-f4aee11494be button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b2328776-fe07-4766-a2e2-f4aee11494be');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"hHUu0aX4poUu"},"source":["# Creating preds.jsonl\n","\n","This section constructs the `preds.jsonl` file which contains model predictions and original annotations in the following json format.\n","\n","\n","```\n","{\n","  \"opinions\": [\n","    {\n","      \"sentiment\": \"Positive\",\n","      \"aspect\": \"safety\",\n","      \"target_entity\": \"LOCATION1\"\n","    }\n","  ],\n","  \"id\": 153,\n","  \"text\": \" LOCATION1 is in Greater London and is a very safe place\",\n","  \"model_pred\": [\n","    {\n","      \"sentiment\": ...,\n","      \"aspect\": ...,\n","      \"target_entity\":...\n","    },...\n","  ]\n","}\n","```"]},{"cell_type":"code","metadata":{"id":"K-oZVA8x0NT6"},"source":["with open('/content/drive/MyDrive/PIL/BERT-ABSA/SentiHood Dataset/sentihood-test.json', 'r') as fp:\n","  testing_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jX-rJsL7pxlE"},"source":["labels_to_sentiment_dict = {\n","    0: 'Positive',\n","    1: 'Negative',\n","    2: 'None'\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIhf2LtSqCOq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653618411370,"user_tz":-420,"elapsed":234273,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"512d665c-c2ac-48a2-e43d-0418cfbbb0cf"},"source":["BERT_MODEL = 'bert-base-uncased'\n","MAX_LEN = 160\n","locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife',\n","           'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","\n","tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Device: {device}\")\n","\n","model = torch.load('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M/Models/0.bin')\n","\n","for each_example in tqdm(testing_set, ncols=80):\n","  id = each_example['id']\n","  text = each_example['text'].strip()\n","\n","  each_example['model_pred'] = []\n","\n","  count_location = 1\n","  for location in locations:\n","    if location in text:\n","      # If \"location\" is present in the text, then utilize the trained model\n","      # to predict the aspects and their corresponding sentiment of the text.\n","\n","      text = text.replace(location, 'location - ' + str(count_location))\n","      \n","      for aspect in aspects:\n","        auxiliary_sentence = f'location - {str(count_location)} - {aspect}'\n","        combined_text = text + ' ' + auxiliary_sentence\n","        \n","        inputs = tokenizer.encode_plus(\n","            combined_text,\n","            add_special_tokens = True,\n","            max_length = MAX_LEN,\n","            pad_to_max_length = True\n","        )\n","        ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).unsqueeze(0)\n","        mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).unsqueeze(0)\n","        token_type_ids = torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long).unsqueeze(0)\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","\n","        outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        predicted = predicted.detach().cpu().numpy()\n","\n","         # If predicted sentiment is not None, then add it to the preds.jsonl.\n","         \n","        if predicted[0] != 2:\n","          result = {\n","              \"sentiment\": labels_to_sentiment_dict[predicted[0]],\n","              \"aspect\": aspect,\n","              \"target_entity\": location\n","          }\n","          each_example['model_pred'].append(result)\n","      \n","    count_location += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                  | 0/1491 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","100%|███████████████████████████████████████| 1491/1491 [03:47<00:00,  6.57it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"37Mqdc9uYlCN"},"source":["with open('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M/pred.jsonl', mode='w', encoding='utf-8') as fp:\n","  for each in testing_set:\n","    json_record = json.dumps(each, ensure_ascii=False)\n","    fp.write(json_record + '\\n')"],"execution_count":null,"outputs":[]}]}