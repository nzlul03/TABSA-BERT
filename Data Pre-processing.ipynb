{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"Data Pre-processing New.ipynb","provenance":[],"collapsed_sections":["HJ-_nYnyLlIi","WksSYv5sLUwo","WnJ50OBTLUxi","36eRzoPzJItx","EgspdpzpLqz1","2j_r2Yyrjsrh","mg1UnHCjL2rt","b3ww6_uSjkSS","zn_TM8ko8XCN","RuDtixFVf009","RSQgnbYFf-FS","Aec1zSLuouce","UoAP9mohklbd","R6Pw-b34VUPR","hmZTMxDvVgQl","3QByiCX5eX9V","06Jy8JLKXM7c","hY6d1L1kUljF","5Q1LGSd4UqgK","l5Afl7pwXHGq"]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"oY79GQATNRqj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653710410766,"user_tz":-420,"elapsed":24683,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"13750322677494561607"}},"outputId":"5776199e-11e8-43ce-be64-b5b56078d107"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"qf4Bv1DJLUwY"},"source":["import json\n","from tqdm import tqdm\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqvsYwwgbb6f","executionInfo":{"status":"ok","timestamp":1653710411285,"user_tz":-420,"elapsed":524,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"13750322677494561607"}},"outputId":"19cf63e7-5ad9-4e5d-cea1-48ab1e7f0aa5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["drive  sample_data\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/BERT-ABSA"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"StLvP2r2bd4i","executionInfo":{"status":"ok","timestamp":1653710411286,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"13750322677494561607"}},"outputId":"7c34df9f-6544-42fe-d6c5-8985d7ebba36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1f6_nh7bnRsASRyQ_pzxXBMOMI-kvHn7x/BERT-ABSA\n"]}]},{"cell_type":"markdown","metadata":{"id":"HJ-_nYnyLlIi"},"source":["# Preparing Datasets for BERT-single\n","\n","For BERT-single, each `location-pair` will have a different 3-class classification model, thus we need to construct a different training and validation set for each `location-pair`. "]},{"cell_type":"markdown","metadata":{"id":"WksSYv5sLUwo"},"source":["## Preparing Training Sets"]},{"cell_type":"code","metadata":{"id":"LpNb-FQHLUwq"},"source":["with open('/content/drive/MyDrive/BERT-ABSA/SentiHood Dataset/sentihood-train.json', 'r') as fp:\n","    training_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WDcOwcmTLUxZ","outputId":"57d369e9-a303-445e-afee-d9a08d6d6680","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653709473070,"user_tz":-420,"elapsed":82046,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"13750322677494561607"}}},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","\n","for location in locations:\n","    for aspect in aspects:\n","        df = pd.DataFrame({'id': [], 'text': [], 'sentiment': []})\n","        \n","        ii = 0\n","        for each_example in training_set:\n","            id = str(int(each_example['id']))\n","            text = each_example['text'].strip()\n","            \n","            # If `location` is present in the text, only then iterate over the  \n","            # list of opinions to find suitable `location-aspect` datapoints.\n","\n","            if location in text:\n","                aspect_found = False\n","                \n","                for opinion in each_example['opinions']:\n","                    # Checking if the current example contains a sentiment\n","                    # related to `location-aspect`\n","                    \n","                    if opinion['target_entity'] == location and opinion['aspect'] == aspect:\n","                        df.loc[ii] = [id, text, opinion['sentiment']]\n","                        aspect_found = True\n","                        ii += 1\n","                        break\n","                \n","                # If no sentiment is found for `location-asppect` in current \n","                # example, then add a datapoint with None.\n","                \n","                if not aspect_found:\n","                    df.loc[ii] = [id, text, 'None']\n","                    ii += 1\n","\n","        df.to_csv('/content/drive/MyDrive/BERT-ABSA/Bert-single/TrainingData/' + str(location) + str(aspect) + '.csv', index=False)\n","        print(f\"{location}{aspect} DONE!\\tLength = {ii}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LOCATION1dining DONE!\tLength = 2977\n","LOCATION1general DONE!\tLength = 2977\n","LOCATION1green-nature DONE!\tLength = 2977\n","LOCATION1live DONE!\tLength = 2977\n","LOCATION1multicultural DONE!\tLength = 2977\n","LOCATION1nightlife DONE!\tLength = 2977\n","LOCATION1price DONE!\tLength = 2977\n","LOCATION1quiet DONE!\tLength = 2977\n","LOCATION1safety DONE!\tLength = 2977\n","LOCATION1shopping DONE!\tLength = 2977\n","LOCATION1touristy DONE!\tLength = 2977\n","LOCATION1transit-location DONE!\tLength = 2977\n","LOCATION2dining DONE!\tLength = 775\n","LOCATION2general DONE!\tLength = 775\n","LOCATION2green-nature DONE!\tLength = 775\n","LOCATION2live DONE!\tLength = 775\n","LOCATION2multicultural DONE!\tLength = 775\n","LOCATION2nightlife DONE!\tLength = 775\n","LOCATION2price DONE!\tLength = 775\n","LOCATION2quiet DONE!\tLength = 775\n","LOCATION2safety DONE!\tLength = 775\n","LOCATION2shopping DONE!\tLength = 775\n","LOCATION2touristy DONE!\tLength = 775\n","LOCATION2transit-location DONE!\tLength = 775\n"]}]},{"cell_type":"markdown","metadata":{"id":"WnJ50OBTLUxi"},"source":["## Preparing Validation Sets"]},{"cell_type":"code","metadata":{"id":"CrXWA9PNLUxk"},"source":["with open('/content/drive/MyDrive/BERT-ABSA/SentiHood Dataset/sentihood-dev.json', 'r') as fp:\n","    validation_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKoTqGstLUx_","outputId":"82828b43-ba8b-4f25-c9ba-9641e77e534b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653710483569,"user_tz":-420,"elapsed":21983,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"13750322677494561607"}}},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","\n","for location in locations:\n","    for aspect in aspects:\n","        df = pd.DataFrame({'id': [], 'text': [], 'sentiment': []})\n","        ii = 0\n","        for each_example in validation_set:\n","            id = str(int(each_example['id']))\n","            text = each_example['text'].strip()\n","            \n","            # If `location` is present in the text, only then iterate over the  \n","            # list of opinions to find suitable `location-aspect` datapoints.\n","\n","            if location in text:\n","                aspect_found = False\n","                for opinion in each_example['opinions']:\n","                    # Checking if the current example contains a sentiment\n","                    # related to `location-aspect`\n","\n","                    if opinion['target_entity'] == location and opinion['aspect'] == aspect:\n","                        df.loc[ii] = [id, text, opinion['sentiment']]\n","                        aspect_found = True\n","                        ii += 1\n","                        break\n","                \n","                # If no sentiment is found for `location-asppect` in current \n","                # example, then add a datapoint with None.\n","\n","                if not aspect_found:\n","                    df.loc[ii] = [id, text, 'None']\n","                    ii += 1\n","\n","        df.to_csv('/content/drive/MyDrive/BERT-ABSA/Bert-single/ValidationData/' + str(location) + str(aspect) + '.csv', index=False)\n","        print(f\"{location}{aspect} DONE!\\tLength = {ii}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LOCATION1dining DONE!\tLength = 747\n","LOCATION1general DONE!\tLength = 747\n","LOCATION1green-nature DONE!\tLength = 747\n","LOCATION1live DONE!\tLength = 747\n","LOCATION1multicultural DONE!\tLength = 747\n","LOCATION1nightlife DONE!\tLength = 747\n","LOCATION1price DONE!\tLength = 747\n","LOCATION1quiet DONE!\tLength = 747\n","LOCATION1safety DONE!\tLength = 747\n","LOCATION1shopping DONE!\tLength = 747\n","LOCATION1touristy DONE!\tLength = 747\n","LOCATION1transit-location DONE!\tLength = 747\n","LOCATION2dining DONE!\tLength = 190\n","LOCATION2general DONE!\tLength = 190\n","LOCATION2green-nature DONE!\tLength = 190\n","LOCATION2live DONE!\tLength = 190\n","LOCATION2multicultural DONE!\tLength = 190\n","LOCATION2nightlife DONE!\tLength = 190\n","LOCATION2price DONE!\tLength = 190\n","LOCATION2quiet DONE!\tLength = 190\n","LOCATION2safety DONE!\tLength = 190\n","LOCATION2shopping DONE!\tLength = 190\n","LOCATION2touristy DONE!\tLength = 190\n","LOCATION2transit-location DONE!\tLength = 190\n"]}]},{"cell_type":"markdown","metadata":{"id":"36eRzoPzJItx"},"source":["## Preparing Testing Sets"]},{"cell_type":"code","metadata":{"id":"U6_j4QJmJT0t"},"source":["with open('/content/drive/MyDrive/BERT-ABSA/SentiHood Dataset/sentihood-test.json', 'r') as fp:\n","    testing_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2utSpvT1JaxV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653709702538,"user_tz":-420,"elapsed":40187,"user":{"displayName":"Nuzulul Khairu Nissa","userId":"13750322677494561607"}},"outputId":"35cf5bbe-0e12-4148-cb62-d74a344fb9ab"},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","\n","for location in locations:\n","    for aspect in aspects:\n","        df = pd.DataFrame({'id': [], 'text': [], 'sentiment': []})\n","        ii = 0\n","        for each_example in testing_set:\n","            id = str(int(each_example['id']))\n","            text = each_example['text'].strip()\n","            \n","            # If `location` is present in the text, only then iterate over the  \n","            # list of opinions to find suitable `location-aspect` datapoints.\n","\n","            if location in text:\n","                aspect_found = False\n","                for opinion in each_example['opinions']:\n","                    # Checking if the current example contains a sentiment\n","                    # related to `location-aspect`\n","\n","                    if opinion['target_entity'] == location and opinion['aspect'] == aspect:\n","                        df.loc[ii] = [id, text, opinion['sentiment']]\n","                        aspect_found = True\n","                        ii += 1\n","                        break\n","                \n","                # If no sentiment is found for `location-asppect` in current \n","                # example, then add a datapoint with None.\n","\n","                if not aspect_found:\n","                    df.loc[ii] = [id, text, 'None']\n","                    ii += 1\n","\n","        df.to_csv('/content/drive/MyDrive/BERT-ABSA/Bert-single/TestingData/' + str(location) + str(aspect) + '.csv', index=False)\n","        print(f\"{location}{aspect} DONE!\\tLength = {ii}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LOCATION1dining DONE!\tLength = 1491\n","LOCATION1general DONE!\tLength = 1491\n","LOCATION1green-nature DONE!\tLength = 1491\n","LOCATION1live DONE!\tLength = 1491\n","LOCATION1multicultural DONE!\tLength = 1491\n","LOCATION1nightlife DONE!\tLength = 1491\n","LOCATION1price DONE!\tLength = 1491\n","LOCATION1quiet DONE!\tLength = 1491\n","LOCATION1safety DONE!\tLength = 1491\n","LOCATION1shopping DONE!\tLength = 1491\n","LOCATION1touristy DONE!\tLength = 1491\n","LOCATION1transit-location DONE!\tLength = 1491\n","LOCATION2dining DONE!\tLength = 388\n","LOCATION2general DONE!\tLength = 388\n","LOCATION2green-nature DONE!\tLength = 388\n","LOCATION2live DONE!\tLength = 388\n","LOCATION2multicultural DONE!\tLength = 388\n","LOCATION2nightlife DONE!\tLength = 388\n","LOCATION2price DONE!\tLength = 388\n","LOCATION2quiet DONE!\tLength = 388\n","LOCATION2safety DONE!\tLength = 388\n","LOCATION2shopping DONE!\tLength = 388\n","LOCATION2touristy DONE!\tLength = 388\n","LOCATION2transit-location DONE!\tLength = 388\n"]}]},{"cell_type":"markdown","metadata":{"id":"EgspdpzpLqz1"},"source":["# Preparing Datasets for BERT-pair\n","\n","For all the BERT-pair models, only a single training, validation and testing set need to constructed."]},{"cell_type":"markdown","metadata":{"id":"2j_r2Yyrjsrh"},"source":["## Datasets for QA-M\n","\n","For QA-M, an auxiliary sentence in the following form will be constructed for each `location-aspect`.\n","\n","*what do you think about `aspect` of `location`?*"]},{"cell_type":"markdown","metadata":{"id":"mg1UnHCjL2rt"},"source":["### Training set for BERT-pair QA-M"]},{"cell_type":"code","metadata":{"id":"fJMO6XbMLwxG"},"source":["with open('/content/drive/My Drive/SentiHood/SentiHood Dataset/sentihood-train.json', 'r') as fp:\n","    training_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d_DjXpAePMs9","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1595988411038,"user_tz":-330,"elapsed":192237,"user":{"displayName":"Nikhil Prakash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh2n3ooINSV1n1kZoSymqxX7GhkFUxPi4tw-pohqA=s64","userId":"14280933032296268011"}},"outputId":"590e9335-bbbe-463d-e911-ce7b505ce03c"},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","\n","df = pd.DataFrame({'id': [], 'text': [], 'auxiliary_sentence': [], 'sentiment': []})\n","ii = 0\n","\n","for location in locations:\n","  for each_example in tqdm(training_set, ncols=80):\n","    id = str(int(each_example['id']))\n","    text = each_example['text'].strip()\n","\n","    # If `location` is present in the text, only then iterate over the  \n","    # list of opinions to find suitable `location-aspect` datapoints.\n","\n","    if location in text:\n","      # current_opinion_aspects: Is a dictionary containing all aspects and  \n","      # their corresponding sentiment present in the current opinion.\n","      current_opinion_aspects = {}\n","      \n","      for opinion in each_example['opinions']:\n","        if opinion['target_entity'] == location:\n","          current_opinion_aspects[opinion['aspect']] = opinion['sentiment']\n","      \n","      for aspect in aspects:\n","        auxiliary_sentence = f'what do you think of the {aspect} of {location}?' \n","        \n","        if aspect in current_opinion_aspects.keys():\n","          df.loc[ii] = [id, text, auxiliary_sentence, current_opinion_aspects[aspect]]\n","        else:\n","          df.loc[ii] = [id, text, auxiliary_sentence, 'None']\n","        ii += 1\n","          "],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 2977/2977 [02:23<00:00, 20.78it/s]\n","100%|██████████| 2977/2977 [00:48<00:00, 61.58it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WRyqc4nLVbwJ"},"source":["# df.to_csv('/content/drive/My Drive/SentiHood/Bert-pair/QA-M/training_set.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b3ww6_uSjkSS"},"source":["### Validation set for BERT-pair QA-M"]},{"cell_type":"code","metadata":{"id":"XQx2iZyjgetn"},"source":["with open('/content/drive/My Drive/SentiHood/SentiHood Dataset/sentihood-dev.json', 'r') as fp:\n","    validation_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QjGyZ-Rmj3hi","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1595993003637,"user_tz":-330,"elapsed":38813,"user":{"displayName":"Nikhil Prakash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh2n3ooINSV1n1kZoSymqxX7GhkFUxPi4tw-pohqA=s64","userId":"14280933032296268011"}},"outputId":"b642ec8d-f19e-41ef-d8ac-9218e42673af"},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","\n","df = pd.DataFrame({'id': [], 'text': [], 'auxiliary_sentence': [], 'sentiment': []})\n","ii = 0\n","\n","for location in locations:\n","  for each_example in tqdm(validation_set, ncols=80):\n","    id = str(int(each_example['id']))\n","    text = each_example['text'].strip()\n","\n","    # If `location` is present in the text, only then iterate over the  \n","    # list of opinions to find suitable `location-aspect` datapoints.\n","\n","    if location in text:\n","      # current_opinion_aspects: Is a dictionary containing all aspects and  \n","      # their corresponding sentiment present in the current opinion.\n","      current_opinion_aspects = {}\n","      \n","      for opinion in each_example['opinions']:\n","        if opinion['target_entity'] == location:\n","          current_opinion_aspects[opinion['aspect']] = opinion['sentiment']\n","      \n","      for aspect in aspects:\n","        auxiliary_sentence = f'what do you think of the {aspect} of {location}?' \n","        if aspect in current_opinion_aspects.keys():\n","          df.loc[ii] = [id, text, auxiliary_sentence, current_opinion_aspects[aspect]]\n","        else:\n","          df.loc[ii] = [id, text, auxiliary_sentence, 'None']\n","        ii += 1\n","          "],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|█████████████████████████████████████████| 747/747 [00:29<00:00, 24.95it/s]\n","100%|█████████████████████████████████████████| 747/747 [00:08<00:00, 92.77it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"lX_IeSNeltjG"},"source":["# df.to_csv('/content/drive/My Drive/SentiHood/Bert-pair/QA-M/validation_set.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zn_TM8ko8XCN"},"source":["### Testing set for BERT-pair QA-M"]},{"cell_type":"code","metadata":{"id":"nMX2sS1dmW95"},"source":["with open('/content/drive/My Drive/SentiHood/SentiHood Dataset/sentihood-test.json', 'r') as fp:\n","    testing_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9y6TsLTw8rO6","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1596032558268,"user_tz":-330,"elapsed":81928,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"69a8a58f-4960-42dd-bb75-4b87619ec996"},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","\n","df = pd.DataFrame({'id': [], 'text': [], 'auxiliary_sentence': [], 'sentiment': []})\n","ii = 0\n","\n","for location in locations:\n","  for each_example in tqdm(testing_set, ncols=80):\n","    id = str(int(each_example['id']))\n","    text = each_example['text'].strip()\n","\n","    # If `location` is present in the text, only then iterate over the  \n","    # list of opinions to find suitable `location-aspect` datapoints.\n","    \n","    if location in text:\n","      # current_opinion_aspects: Is a dictionary containing all aspects and  \n","      # their corresponding sentiment present in the current opinion.\n","\n","      current_opinion_aspects = {}\n","      for opinion in each_example['opinions']:\n","        if opinion['target_entity'] == location:\n","          current_opinion_aspects[opinion['aspect']] = opinion['sentiment']\n","      \n","      for aspect in aspects:\n","        auxiliary_sentence = f'what do you think of the {aspect} of {location}?' \n","        if aspect in current_opinion_aspects.keys():\n","          df.loc[ii] = [id, text, auxiliary_sentence, current_opinion_aspects[aspect]]\n","        else:\n","          df.loc[ii] = [id, text, auxiliary_sentence, 'None']\n","        ii += 1\n","          "],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|███████████████████████████████████████| 1491/1491 [01:02<00:00, 23.71it/s]\n","100%|███████████████████████████████████████| 1491/1491 [00:17<00:00, 83.23it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"en2g97-49L4r"},"source":["# df.to_csv('/content/drive/My Drive/SentiHood/Bert-pair/QA-M/testing_set.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RuDtixFVf009"},"source":["## Datasets for NLI-M\n","\n","For NLI-M, an auxiliary pseudo-sentence is the following form will be constructed for each `location-aspect`.\n","\n","*`location` - `aspect`* where `location` will be reformed as `location - 1` and `location - 2`."]},{"cell_type":"markdown","metadata":{"id":"RSQgnbYFf-FS"},"source":["### Training set for BERT-pair NLI-M"]},{"cell_type":"code","metadata":{"id":"GBHmjLPaf6tN"},"source":["with open('/content/drive/MyDrive/PIL/BERT-ABSA/SentiHood Dataset/sentihood-train.json', 'r') as fp:\n","    training_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P02JxTGJgFcL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653575580919,"user_tz":-420,"elapsed":134397,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"28b5489b-5581-4f0b-8db7-2b3a4dd239be"},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife',\n","           'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","\n","df = pd.DataFrame({'id': [], 'text': [], 'auxiliary_sentence': [], 'sentiment': []})\n","ii = 0\n","\n","count_location = 1\n","for location in locations:\n","  for each_example in tqdm(training_set, ncols=80):\n","    id = str(int(each_example['id']))\n","    text = each_example['text'].strip()\n","\n","    # If `location` is present in the text, only then iterate over the  \n","    # list of opinions to find suitable `location-aspect` datapoints.\n","\n","    if location in text:\n","      # current_opinion_aspects: Is a dictionary containing all aspects and  \n","      # their corresponding sentiment present in the current opinion.\n","      current_opinion_aspects = {}\n","\n","      for opinion in each_example['opinions']:\n","        if opinion['target_entity'] == location:\n","          current_opinion_aspects[opinion['aspect']] = opinion['sentiment']\n","      \n","      for aspect in aspects:\n","        auxiliary_sentence = f\"location - {str(count_location)} - {aspect}\"\n","        text = text.replace(location, 'location - ' + str(count_location))\n","        \n","        if aspect in current_opinion_aspects.keys():\n","          df.loc[ii] = [id, text, auxiliary_sentence, current_opinion_aspects[aspect]]\n","        else:\n","          df.loc[ii] = [id, text, auxiliary_sentence, 'None']\n","        ii += 1\n","    \n","  count_location += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████| 2977/2977 [01:38<00:00, 30.35it/s]\n","100%|███████████████████████████████████████| 2977/2977 [00:36<00:00, 82.67it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"oJtYHDdDiDmA"},"source":["df.to_csv('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M/Datasets/training_set.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Aec1zSLuouce"},"source":["### Validation set for BERT-pair NLI-M"]},{"cell_type":"code","metadata":{"id":"eqHXsnYbm79o"},"source":["with open('/content/drive/MyDrive/PIL/BERT-ABSA/SentiHood Dataset/sentihood-dev.json', 'r') as fp:\n","    validation_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tT_DAuuco25i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653575729700,"user_tz":-420,"elapsed":23872,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"a0e58a42-8ef1-4746-8aaf-ce687c7b6aaa"},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife',\n","           'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","\n","df = pd.DataFrame({'id': [], 'text': [], 'auxiliary_sentence': [], 'sentiment': []})\n","ii = 0\n","\n","count_location = 1\n","for location in locations:\n","  for each_example in tqdm(validation_set, ncols=80):\n","    id = str(int(each_example['id']))\n","    text = each_example['text'].strip()\n","\n","    # If `location` is present in the text, only then iterate over the  \n","    # list of opinions to find suitable `location-aspect` datapoints.\n","\n","    if location in text:\n","      # current_opinion_aspects: Is a dictionary containing all aspects and  \n","      # their corresponding sentiment present in the current opinion.\n","      current_opinion_aspects = {}\n","\n","      for opinion in each_example['opinions']:\n","        if opinion['target_entity'] == location:\n","          current_opinion_aspects[opinion['aspect']] = opinion['sentiment']\n","      \n","      for aspect in aspects:\n","        auxiliary_sentence = f\"location - {str(count_location)} - {aspect}\"\n","        text = text.replace(location, 'location - ' + str(count_location))\n","        \n","        if aspect in current_opinion_aspects.keys():\n","          df.loc[ii] = [id, text, auxiliary_sentence, current_opinion_aspects[aspect]]\n","        else:\n","          df.loc[ii] = [id, text, auxiliary_sentence, 'None']\n","        ii += 1\n","    \n","  count_location += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|█████████████████████████████████████████| 747/747 [00:18<00:00, 40.69it/s]\n","100%|████████████████████████████████████████| 747/747 [00:05<00:00, 144.17it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"8KBLuKtPo_Y2"},"source":["df.to_csv('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M/Datasets/validation_set.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UoAP9mohklbd"},"source":["### Testing set for BERT-pair NLI-M "]},{"cell_type":"code","metadata":{"id":"WONz_7CwpLad"},"source":["with open('/content/drive/MyDrive/PIL/BERT-ABSA/SentiHood Dataset/sentihood-test.json', 'r') as fp:\n","    testing_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"55YuOxfDkwm-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653575787970,"user_tz":-420,"elapsed":54083,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"2aad8a44-f62f-40a7-c98e-a755bf30f1e1"},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife',\n","           'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","\n","df = pd.DataFrame({'id': [], 'text': [], 'auxiliary_sentence': [], 'sentiment': []})\n","ii = 0\n","\n","count_location = 1\n","for location in locations:\n","  for each_example in tqdm(testing_set, ncols=80):\n","    id = str(int(each_example['id']))\n","    text = each_example['text'].strip()\n","\n","    # If `location` is present in the text, only then iterate over the  \n","    # list of opinions to find suitable `location-aspect` datapoints.\n","\n","    if location in text:\n","      # current_opinion_aspects: Is a dictionary containing all aspects and  \n","      # their corresponding sentiment present in the current opinion.\n","      current_opinion_aspects = {}\n","\n","      for opinion in each_example['opinions']:\n","        if opinion['target_entity'] == location:\n","          current_opinion_aspects[opinion['aspect']] = opinion['sentiment']\n","      \n","      for aspect in aspects:\n","        auxiliary_sentence = f\"location - {str(count_location)} - {aspect}\"\n","        text = text.replace(location, 'location - ' + str(count_location))\n","        \n","        if aspect in current_opinion_aspects.keys():\n","          df.loc[ii] = [id, text, auxiliary_sentence, current_opinion_aspects[aspect]]\n","        else:\n","          df.loc[ii] = [id, text, auxiliary_sentence, 'None']\n","        ii += 1\n","    \n","  count_location += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████| 1491/1491 [00:40<00:00, 36.95it/s]\n","100%|██████████████████████████████████████| 1491/1491 [00:13<00:00, 113.73it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"vax7je3Km2uQ"},"source":["df.to_csv('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-M/Datasets/testing_set.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R6Pw-b34VUPR"},"source":["## Datasets for QA-B\n","\n","For QA-B, 3 auxiliary sentences in the following form will be constructed for each `location-aspect`.\n","\n","*the polarity of the aspect `aspect` of `location` is `positive|negative|none`*."]},{"cell_type":"markdown","metadata":{"id":"hmZTMxDvVgQl"},"source":["### Training set for BERT-pair QA-B"]},{"cell_type":"code","metadata":{"id":"7uO-4GB5nP4J"},"source":["with open('/content/drive/My Drive/SentiHood/SentiHood Dataset/sentihood-train.json', 'r') as fp:\n","    training_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xQkGGnm9VquY","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1596199684532,"user_tz":-330,"elapsed":290698,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"6c70104d-0e4e-4213-e6c6-984500133335"},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","\n","df = pd.DataFrame({'id': [], 'text': [], 'auxiliary_sentence': [], 'sentiment': []})\n","ii = 0\n","\n","count_location = 1\n","for location in locations:\n","  for each_example in tqdm(training_set, ncols=80):\n","    id = str(int(each_example['id']))\n","    text = each_example['text'].strip()\n","\n","    # If `location` is present in the text, only then iterate over the  \n","    # list of opinions to find suitable `location-aspect` datapoints.\n","\n","    if location in text:\n","      # current_opinion_aspects: Is a dictionary containing all aspects and  \n","      # their corresponding sentiment present in the current opinion.\n","\n","      current_opinion_aspects = {}\n","      for opinion in each_example['opinions']:\n","        if opinion['target_entity'] == location:\n","          current_opinion_aspects[opinion['aspect']] = opinion['sentiment']\n","      \n","      text = text.replace(location, 'location - ' + str(count_location))\n","      \n","      for aspect in aspects:\n","        aspect_found = False\n","        \n","        for polarity in ['Positive', 'Negative']:\n","          auxiliary_sentence = f\"the polarity of the aspect {aspect} of location - {str(count_location)} is {polarity}.\"\n","          \n","          if aspect in current_opinion_aspects.keys() and current_opinion_aspects[aspect] == polarity:\n","            df.loc[ii] = [id, text, auxiliary_sentence, int(1)]\n","            ii += 1\n","            aspect_found = True\n","          else:\n","            df.loc[ii] = [id, text, auxiliary_sentence, int(0)]\n","            ii += 1\n","        \n","        # If no sentiment is found for the `location-aspect`, then add the \n","        # auxiliary sentence with None to the dataset.\n","        \n","        auxiliary_sentence = f\"the polarity of the aspect {aspect} of location - {str(count_location)} is None.\"\n","        if not aspect_found:\n","          df.loc[ii] = [id, text, auxiliary_sentence, int(1)]\n","          ii += 1\n","        else:\n","          df.loc[ii] = [id, text, auxiliary_sentence, int(0)]\n","          ii += 1\n","    \n","  count_location += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|███████████████████████████████████████| 2977/2977 [13:51<00:00,  3.58it/s]\n","100%|███████████████████████████████████████| 2977/2977 [06:59<00:00,  7.09it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"fkMTRULiYOuH"},"source":["df['sentiment'] = df['sentiment'].astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"83zIDzuTdD1L"},"source":["# df.to_csv('/content/drive/My Drive/SentiHood/Bert-pair/QA-B/Datasets/training_set.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3QByiCX5eX9V"},"source":["### Validation set for BERT-pair QA-B"]},{"cell_type":"code","metadata":{"id":"iPvFDsajeJ2p"},"source":["with open('/content/drive/My Drive/SentiHood/SentiHood Dataset/sentihood-dev.json', 'r') as fp:\n","    validation_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jMZoTRrUefo7","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1596199920772,"user_tz":-330,"elapsed":150082,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"9b44e21e-18d3-41c0-f18b-917dd3b42eef"},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","\n","df = pd.DataFrame({'id': [], 'text': [], 'auxiliary_sentence': [], 'sentiment': []})\n","ii = 0\n","\n","count_location = 1\n","for location in locations:\n","  for each_example in tqdm(validation_set, ncols=80):\n","    id = str(int(each_example['id']))\n","    text = each_example['text'].strip()\n","\n","    # If `location` is present in the text, only then iterate over the  \n","    # list of opinions to find suitable `location-aspect` datapoints.\n","    \n","    if location in text:\n","      # current_opinion_aspects: Is a dictionary containing all aspects and  \n","      # their corresponding sentiment present in the current opinion.\n","\n","      current_opinion_aspects = {}\n","      for opinion in each_example['opinions']:\n","        if opinion['target_entity'] == location:\n","          current_opinion_aspects[opinion['aspect']] = opinion['sentiment']\n","      \n","      text = text.replace(location, 'location - ' + str(count_location))\n","      \n","      for aspect in aspects:\n","        aspect_found = False\n","        \n","        for polarity in ['Positive', 'Negative']:\n","          auxiliary_sentence = f\"the polarity of the aspect {aspect} of location - {str(count_location)} is {polarity}.\"\n","          \n","          if aspect in current_opinion_aspects.keys() and current_opinion_aspects[aspect] == polarity:\n","            df.loc[ii] = [id, text, auxiliary_sentence, int(1)]\n","            ii += 1\n","            aspect_found = True\n","          else:\n","            df.loc[ii] = [id, text, auxiliary_sentence, int(0)]\n","            ii += 1\n","        \n","        # If no sentiment is found for the `location-aspect`, then add the \n","        # auxiliary sentence with None to the dataset.\n","\n","        auxiliary_sentence = f\"the polarity of the aspect {aspect} of location - {str(count_location)} is None.\"\n","        if not aspect_found:\n","          df.loc[ii] = [id, text, auxiliary_sentence, int(1)]\n","          ii += 1\n","        else:\n","          df.loc[ii] = [id, text, auxiliary_sentence, int(0)]\n","          ii += 1\n","    \n","  count_location += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|█████████████████████████████████████████| 747/747 [01:53<00:00,  6.60it/s]\n","100%|█████████████████████████████████████████| 747/747 [00:36<00:00, 20.61it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-WnxHoWsDqqo"},"source":["df['sentiment'] = df['sentiment'].astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ekpQlCDfgpW"},"source":["# df.to_csv('/content/drive/My Drive/SentiHood/Bert-pair/QA-B/Datasets/validation_set.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"06Jy8JLKXM7c"},"source":["### Testing set for BERT-pair QA-B "]},{"cell_type":"code","metadata":{"id":"i-YUuV1gXMHP"},"source":["with open('/content/drive/My Drive/SentiHood/SentiHood Dataset/sentihood-test.json', 'r') as fp:\n","    testing_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2hxcy5xefuRw","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1596250719156,"user_tz":-330,"elapsed":426665,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"99394567-faf2-461b-c6fc-7e56467e642d"},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","\n","df = pd.DataFrame({'id': [], 'text': [], 'auxiliary_sentence': [], 'sentiment': []})\n","ii = 0\n","\n","count_location = 1\n","for location in locations:\n","  for each_example in tqdm(testing_set, ncols=80):\n","    id = str(int(each_example['id']))\n","    text = each_example['text'].strip()\n","\n","    # If `location` is present in the text, only then iterate over the  \n","    # list of opinions to find suitable `location-aspect` datapoints.\n","\n","    if location in text:\n","      # current_opinion_aspects: Is a dictionary containing all aspects and  \n","      # their corresponding sentiment present in the current opinion.\n","\n","      current_opinion_aspects = {}\n","      for opinion in each_example['opinions']:\n","        if opinion['target_entity'] == location:\n","          current_opinion_aspects[opinion['aspect']] = opinion['sentiment']\n","      \n","      text = text.replace(location, 'location - ' + str(count_location))\n","      \n","      for aspect in aspects:\n","        aspect_found = False\n","        \n","        for polarity in ['Positive', 'Negative']:\n","          auxiliary_sentence = f\"the polarity of the aspect {aspect} of location - {str(count_location)} is {polarity}.\"\n","          \n","          if aspect in current_opinion_aspects.keys() and current_opinion_aspects[aspect] == polarity:\n","            df.loc[ii] = [id, text, auxiliary_sentence, int(1)]\n","            ii += 1\n","            aspect_found = True\n","          else:\n","            df.loc[ii] = [id, text, auxiliary_sentence, int(0)]\n","            ii += 1\n","        \n","        # If no sentiment is found for the `location-aspect`, then add the \n","        # auxiliary sentence with None to the dataset.\n","        \n","        auxiliary_sentence = f\"the polarity of the aspect {aspect} of location - {str(count_location)} is None.\"\n","        if not aspect_found:\n","          df.loc[ii] = [id, text, auxiliary_sentence, int(1)]\n","          ii += 1\n","        else:\n","          df.loc[ii] = [id, text, auxiliary_sentence, int(0)]\n","          ii += 1\n","    \n","  count_location += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|███████████████████████████████████████| 1491/1491 [04:55<00:00,  5.04it/s]\n","100%|███████████████████████████████████████| 1491/1491 [02:10<00:00, 11.46it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mBUv4P5yaNEa"},"source":["df['sentiment'] = df['sentiment'].astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gwgJ3xcMdHc3"},"source":["# df.to_csv('/content/drive/My Drive/SentiHood/Bert-pair/QA-B/Datasets/testing_set.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hY6d1L1kUljF"},"source":["## Datasets for NLI-B\n","\n","For NLI-B, 3 auxiliary pseudo-sentences in the following form will be constructed for each `location-aspect`.\n","\n","*`location` - `aspect` - `polarity`*"]},{"cell_type":"markdown","metadata":{"id":"5Q1LGSd4UqgK"},"source":["### Training set for BERT-pair NLI-B"]},{"cell_type":"code","metadata":{"id":"VsDWHrRB9dSN"},"source":["with open('/content/drive/MyDrive/PIL/BERT-ABSA/SentiHood Dataset/sentihood-train.json', 'r') as fp:\n","    training_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QB-fXiGIU3K0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"704e9c86-634c-43a3-978a-e5682c91c2c3","executionInfo":{"status":"ok","timestamp":1653576506805,"user_tz":-420,"elapsed":689156,"user":{"displayName":"project colab","userId":"14559293068416285175"}}},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife',\n","           'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","\n","df = pd.DataFrame({'id': [], 'text': [], 'auxiliary_sentence': [], 'sentiment': []})\n","ii = 0\n","\n","count_location = 1\n","for location in locations:\n","  for each_example in tqdm(training_set, ncols=80):\n","    id = str(int(each_example['id']))\n","    text = each_example['text'].strip()\n","\n","    # If `location` is present in the text, only then iterate over the  \n","    # list of opinions to find suitable `location-aspect` datapoints.\n","\n","    if location in text:\n","      # current_opinion_aspects: Is a dictionary containing all aspects and  \n","      # their corresponding sentiment present in the current opinion.\n","\n","      current_opinion_aspects = {}\n","      for opinion in each_example['opinions']:\n","        if opinion['target_entity'] == location:\n","          current_opinion_aspects[opinion['aspect']] = opinion['sentiment']\n","      \n","      text = text.replace(location, 'location - ' + str(count_location))\n","      \n","      for aspect in aspects:\n","        aspect_found = False\n","        \n","        for polarity in ['Positive', 'Negative']:\n","          auxiliary_sentence = f\"location - {str(count_location)} - {aspect} - {polarity}.\"\n","          \n","          if aspect in current_opinion_aspects.keys() and current_opinion_aspects[aspect] == polarity:\n","            df.loc[ii] = [id, text, auxiliary_sentence, int(1)]\n","            ii += 1\n","            aspect_found = True\n","          else:\n","            df.loc[ii] = [id, text, auxiliary_sentence, int(0)]\n","            ii += 1\n","        \n","        # If no sentiment is found for the `location-aspect`, then add the \n","        # auxiliary sentence with None to the dataset.\n","        \n","        auxiliary_sentence = f\"location - {str(count_location)} - {aspect} - None.\"\n","        if not aspect_found:\n","          df.loc[ii] = [id, text, auxiliary_sentence, int(1)]\n","          ii += 1\n","        else:\n","          df.loc[ii] = [id, text, auxiliary_sentence, int(0)]\n","          ii += 1\n","    \n","  count_location += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████| 2977/2977 [07:52<00:00,  6.31it/s]\n","100%|███████████████████████████████████████| 2977/2977 [03:36<00:00, 13.73it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"dyBGvaABVbJL"},"source":["df['sentiment'] =  df['sentiment'].astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vFyYLzM5Vi8-"},"source":["df.to_csv('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-B/Datasets/training_set.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l5Afl7pwXHGq"},"source":["### Validation set for BERT-pair NLI-B"]},{"cell_type":"code","metadata":{"id":"1tzn7aQFXLAu"},"source":["with open('/content/drive/MyDrive/PIL/BERT-ABSA/SentiHood Dataset/sentihood-dev.json', 'r') as fp:\n","    validation_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GWndyG8IXQAX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653576771135,"user_tz":-420,"elapsed":95022,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"1e662280-b44f-4077-ab6a-88faa7960ff2"},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife',\n","           'price','quiet', 'safety','shopping', 'touristy', 'transit-location']\n","\n","df = pd.DataFrame({'id': [], 'text': [], 'auxiliary_sentence': [], 'sentiment': []})\n","ii = 0\n","\n","count_location = 1\n","for location in locations:\n","  for each_example in tqdm(validation_set, ncols=80):\n","    id = str(int(each_example['id']))\n","    text = each_example['text'].strip()\n","\n","    # If `location` is present in the text, only then iterate over the  \n","    # list of opinions to find suitable `location-aspect` datapoints.\n","\n","    if location in text:\n","      # current_opinion_aspects: Is a dictionary containing all aspects and  \n","      # their corresponding sentiment present in the current opinion.\n","\n","      current_opinion_aspects = {}\n","      for opinion in each_example['opinions']:\n","        if opinion['target_entity'] == location:\n","          current_opinion_aspects[opinion['aspect']] = opinion['sentiment']\n","      \n","      text = text.replace(location, 'location - ' + str(count_location))\n","      \n","      for aspect in aspects:\n","        aspect_found = False\n","        \n","        for polarity in ['Positive', 'Negative']:\n","          auxiliary_sentence = f\"location - {str(count_location)} - {aspect} - {polarity}.\"\n","          \n","          if aspect in current_opinion_aspects.keys() and current_opinion_aspects[aspect] == polarity:\n","            df.loc[ii] = [id, text, auxiliary_sentence, int(1)]\n","            ii += 1\n","            aspect_found = True\n","          else:\n","            df.loc[ii] = [id, text, auxiliary_sentence, int(0)]\n","            ii += 1\n","        \n","        # If no sentiment is found for the `location-aspect`, then add the \n","        # auxiliary sentence with None to the dataset.\n","        \n","        auxiliary_sentence = f\"location - {str(count_location)} - {aspect} - None.\"\n","        if not aspect_found:\n","          df.loc[ii] = [id, text, auxiliary_sentence, int(1)]\n","          ii += 1\n","        else:\n","          df.loc[ii] = [id, text, auxiliary_sentence, int(0)]\n","          ii += 1\n","    \n","  count_location += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|█████████████████████████████████████████| 747/747 [01:11<00:00, 10.40it/s]\n","100%|█████████████████████████████████████████| 747/747 [00:22<00:00, 32.70it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"fXK0Yt-fXpQm"},"source":["df['sentiment'] =  df['sentiment'].astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VZ1WMrBcXpyQ"},"source":["df.to_csv('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-B/Datasets/validation_set.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZss4EK7UPkD"},"source":["### Testing set for BERT-pair NLI-B"]},{"cell_type":"code","metadata":{"id":"oRh7bxW8X5sh"},"source":["with open('/content/drive/MyDrive/PIL/BERT-ABSA/SentiHood Dataset/sentihood-test.json', 'r') as fp:\n","    testing_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdHLlUXqUXm9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653577115422,"user_tz":-420,"elapsed":236493,"user":{"displayName":"project colab","userId":"14559293068416285175"}},"outputId":"0e0fc400-dc2a-4b98-e280-8eda1677a91d"},"source":["locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife',\n","           'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","\n","df = pd.DataFrame({'id': [], 'text': [], 'auxiliary_sentence': [], 'sentiment': []})\n","ii = 0\n","\n","count_location = 1\n","for location in locations:\n","  for each_example in tqdm(testing_set, ncols=80):\n","    id = str(int(each_example['id']))\n","    text = each_example['text'].strip()\n","\n","    # If `location` is present in the text, only then iterate over the  \n","    # list of opinions to find suitable `location-aspect` datapoints.\n","\n","    if location in text:\n","      # current_opinion_aspects: Is a dictionary containing all aspects and  \n","      # their corresponding sentiment present in the current opinion.\n","\n","      current_opinion_aspects = {}\n","      for opinion in each_example['opinions']:\n","        if opinion['target_entity'] == location:\n","          current_opinion_aspects[opinion['aspect']] = opinion['sentiment']\n","      \n","      text = text.replace(location, 'location - ' + str(count_location))\n","      \n","      for aspect in aspects:\n","        aspect_found = False\n","        \n","        for polarity in ['Positive', 'Negative']:\n","          auxiliary_sentence = f\"location - {str(count_location)} - {aspect} - {polarity}.\"\n","          \n","          if aspect in current_opinion_aspects.keys() and current_opinion_aspects[aspect] == polarity:\n","            df.loc[ii] = [id, text, auxiliary_sentence, int(1)]\n","            ii += 1\n","            aspect_found = True\n","          else:\n","            df.loc[ii] = [id, text, auxiliary_sentence, int(0)]\n","            ii += 1\n","        \n","        # If no sentiment is found for the `location-aspect`, then add the \n","        # auxiliary sentence with None to the dataset.\n","        \n","        auxiliary_sentence = f\"location - {str(count_location)} - {aspect} - None.\"\n","        if not aspect_found:\n","          df.loc[ii] = [id, text, auxiliary_sentence, int(1)]\n","          ii += 1\n","        else:\n","          df.loc[ii] = [id, text, auxiliary_sentence, int(0)]\n","          ii += 1\n","    \n","  count_location += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████| 1491/1491 [02:50<00:00,  8.77it/s]\n","100%|███████████████████████████████████████| 1491/1491 [01:06<00:00, 22.55it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"p58TqalzUtGI"},"source":["df['sentiment'] =  df['sentiment'].astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z_R37bEsWGFB"},"source":["df.to_csv('/content/drive/MyDrive/PIL/BERT-ABSA/Bert-pair/NLI-B/Datasets/testing_set.csv', index=False)"],"execution_count":null,"outputs":[]}]}
